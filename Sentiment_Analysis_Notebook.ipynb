{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE-i_DI0XG9E"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This assignment aims to provide a glimpse of the process of text preprocessing and the procedure of building a fully connected feedforward neural network to understand text.  We will also build another conventional supervised learning model for performance comparison. To obtain a relatively optimal model of neural networks, you need to tune hyperparameters associated the network. \n",
    "\n",
    "# Background\n",
    "\n",
    "This assignment is based on Sentiment Analysis.  Sentiment analysis is one of the popular and highly useful applications in today's world, especially in the digital world. It is used in different fields, such as social media monitoring and market research. \n",
    "\n",
    "\n",
    "# Data \n",
    "\n",
    "To undertake these tasks, we will be using a data set – Cornell Sentence Polarity Dataset. \n",
    "\n",
    "This data was first introduced by Bo Pang and Lillian Lee in a research paper titled ‘Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.’ Published at ACL 2005. \n",
    "\n",
    "The starter notebook dataset contains 5331 positive and 5331 negative snippets of movie reviews. Authors assumed snippets (from Rotten Tomatoes webpages) for reviews marked with ‘fresh’ are positive, and those for reviews marked with ‘rotten’ are negative. \n",
    "\n",
    "# Problem Statement\n",
    "\n",
    "You have to predict the sentiment of each review snippet, whether the review snippet is a positive or a negative one.\n",
    "\n",
    "\n",
    "Specifically in this assignment, you are going to build two models: \n",
    "  - One conventional supervised learning model (non-neural network-based)\n",
    "  - One deep learning based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myxwVfa13Fs0"
   },
   "source": [
    "## How to use this Stub Notebook\n",
    "\n",
    "- This notebook provides an overall structure to your assignment, and ensures that you are on the right track towards the end solution. You would find:\n",
    "\n",
    "     - Each of the overall tasks for the assignment\n",
    "     - A breakdown of the necessary steps to complete each task\n",
    "     - Recommended approaches to solve each of the steps\n",
    "     - Checklist to ensure that you're on the right track\n",
    "\n",
    "- Note that there's no single correct approach to solve this assignment. Your approach would be evaluated fairly as long as the broad direction is correct, and you are able to achieve optimal results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lthtl__bN2jc"
   },
   "source": [
    "## Task I - Represent each review using an N-gram model\n",
    "\n",
    "For this task, you will perform the following steps:\n",
    "\n",
    "- Data Loading\n",
    "  - Import the necessary libraries\n",
    "  - Load the dataset\n",
    "\n",
    "- Use NLP techniques to preprocess the data set\n",
    "    - Tokenization and Stopword removal\n",
    "    - Stemming\n",
    "    - Lemmatization\n",
    "- Convert each document (i.e., a review) into a numeric vector using an N-gram model, in particular, the **Tf-Idf**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcj3UCOe72sC"
   },
   "source": [
    "## Guidelines\n",
    "\n",
    "To perform the above tasks and sub-tasks, perform the following steps:\n",
    "\n",
    "- Load the necessary libraries and methods for this assignment\n",
    "  - Loading and working with data sets - *pandas* and *NumPy*\n",
    "  - Visualizing data - *pyplot* (from *matplotlib*) and *seaborn*\n",
    "  - NLP techniques - To perform the text processing techniques use `nltk`. Also, download the necessary methods and corpuses from `nltk` for performing the steps such as  \n",
    "    - Tokenization\n",
    "    - Stop word removal\n",
    "    - Stemming and Lemmatization\n",
    "  -  Processing data:\n",
    "    - *LabelEncoder* (from *sklearn.preprocessing*)\n",
    "    - *train_test_split* (from *sklearn.model_selection*)\n",
    "  - Conventional Machine Learning Models: Load the necessary packages for creating and evaluating the conventional machine learning models such as \n",
    "    - Logistic Regression\n",
    "    - Decision Tree\n",
    "    - Random Forests\n",
    "    - kNN\n",
    "\n",
    "  - Deep Learning Models: Import the necessary packages and methods for creating deep learning models\n",
    "    - *tensorflow*\n",
    "    - *keras*\n",
    "    - all the necessary submodules and methods from the above to train and evaluate neural networks modules\n",
    "  - Suppressing warnings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-no7l22nFOCo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\rohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Importing libraries for NLP techniques to pre-process data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, mean_squared_error, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Importing packages for building conventional supervised learning models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier \n",
    "\n",
    "# Import methods for building neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Import 'KerasClassifier' from 'keras' for connecting neural networks with 'sklearn' and 'GridSearchCV'\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wt2nBg9fRHoO"
   },
   "outputs": [],
   "source": [
    "# Write code to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrgXT_f0RJbO"
   },
   "source": [
    " - Load the dataset and check a few reviews\n",
    "     - If you're using your local machine, make sure that the data set is in the right folder\n",
    "     - If you're using Google colab you can simply the upload the csv file containing the data to your Google Drive and mount your Google Drive in your Colab VM to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ud1zs_4FSQu7"
   },
   "outputs": [],
   "source": [
    "# Write code to read the dataset\n",
    "df = pd.read_csv('reviewsdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GR5i6GIEYV0s"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Label\n",
       "0  the rock is destined to be the 21st century's ...   pos\n",
       "1  the gorgeously elaborate continuation of \" the...   pos\n",
       "2                     effective but too-tepid biopic   pos\n",
       "3  if you sometimes like to go to the movies to h...   pos\n",
       "4  emerges as something rare , an issue movie tha...   pos"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7jPn0T1P76W"
   },
   "source": [
    "### Tokenization and Stopwords removal\n",
    "\n",
    "---\n",
    "\n",
    " - Initialize the tokenizer that you'll use. Note: This will impact your overall model building process.\n",
    " - Load the stop words from the nltk stopwords corpus and store it in a list *stopword_list*\n",
    " - Write a function `remove_stopwords` that takes a piece of text, tokenizes it and removes all the stopwords using the *stopword_list*\n",
    "  - Input: a piece of text (`str`)\n",
    "  - Output: the same piece of text, tokenized and with the stopwords removed.\n",
    " - Apply the function on a few rows from the data set and observe the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VVCMIBomTVZA"
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer. You can try out a few methods from the nltk.tokenize module and see which one performs best\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "# Setting English stopwords\n",
    "stopword_list = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "M7ZUHjLrY1ce"
   },
   "outputs": [],
   "source": [
    "# Define a function \"remove_stopwords\" that takes a piece of text as input and outputs the tokenized version along with the stopwords removed.\n",
    "# You should use the tokenizer and \"stopword_list\" that you created in the previous code cells for developing this function\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stopword_list] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vyKrbf6XUOs5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock', 'destined', 'st', 'century', 'new', 'conan', 'going', 'make', 'splash', 'even', 'greater', 'arnold', 'schwarzenegger', 'jean', 'claud', 'van', 'damme', 'steven', 'segal']\n",
      "['effective', 'tepid', 'biopic']\n"
     ]
    }
   ],
   "source": [
    "# Removing the stopwords\n",
    "data = df.Review.values.tolist()\n",
    "\n",
    "# Apply function on review column\n",
    "data_words = remove_stopwords(data)\n",
    "print(data_words[0])\n",
    "print(data_words[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU5klz59Yks1"
   },
   "source": [
    "**Checklist**:\n",
    "\n",
    "Check whether the function `remove_stopwords` is working as intended.\n",
    "- Is it tokenizing the review snippet correctly?\n",
    "- Are the unnecessary characters and stopwords removed?\n",
    "\n",
    "Before applying the function on the entire data set, see if you can improve the tokenizer and/or your stopword list further.\n",
    "\n",
    "**References**:\n",
    "\n",
    "In case your tokenizer isn't performing satisfactorily, or if you're getting errors,  You can check out the following links for your reference\n",
    "  - You can use `toktok Tokenizer` [Here's a link](https://www.nltk.org/api/nltk.tokenize.toktok.html) for your reference.\n",
    "  - You might have to download `punkt` module in case you are getting errors. [Here's a link](https://www.nltk.org/api/nltk.tokenize.punkt.html) for your reference\n",
    "\n",
    "**Next Steps**:\n",
    "\n",
    "Once you're done with the verification and improvisation, the next step is to apply the `remove_stopwords` on the entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "E1ksSF5zYjwf"
   },
   "outputs": [],
   "source": [
    "# Apply \"remove_stopwords\" on all the reviews in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI2T9TBxQzhi"
   },
   "source": [
    "### Stemming\n",
    "\n",
    "- Initialize the stemmer that you're going to use. We recommend using `PorterStemmer` from `nltk.porter` module\n",
    "- Create a function `simple_stemmer` that takes a given piece of text and outputs the stemmed version of the individual words using the stemmer initialized earlier\n",
    "    - Input: a piece of text (`str`)\n",
    "    - Output: stemmed version of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nQiYtOMgs6Se"
   },
   "outputs": [],
   "source": [
    "# Initialize the stemmer\n",
    "\n",
    "porter = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a0Keda2BUIL1"
   },
   "outputs": [],
   "source": [
    "# Define \"simple_stemmer\"\n",
    "def simple_stemmer(lists):\n",
    "    return [[porter.stem(word) for word in x] for x in lists]\n",
    "# Apply function on a few reviews\n",
    "sample_stemmer = simple_stemmer(data_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8NUlFeUrhvC"
   },
   "source": [
    "Checklist and Next Steps:\n",
    "\n",
    "- Check if the `simple_stemmer` function is working as intended. Once verified, go ahead and apply it on the entire reviews column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Fcb7dy_3sDA6"
   },
   "outputs": [],
   "source": [
    "# Apply \"simple_stemmer\" on all the reviews in the dataset\n",
    "data_stemmed = simple_stemmer(data_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMyWQU7nRbm4"
   },
   "source": [
    "### Lemmatization\n",
    "\n",
    "- Initialize the Lemmatized that you're going to use. We recommend using 'WordNetLemmatizer'\n",
    "- Create a function `simple_lemmatize` that takes a given piece of text and outputs the lemmatizedd version of the individual words using the lemmatizer initialized earlier\n",
    "    - Input: a piece of text (`str`)\n",
    "    - Output: lemmatized version of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "G25EUAPzs2U6"
   },
   "outputs": [],
   "source": [
    "#Initialize the lemmatizer\n",
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PKSQM1VXRe7x"
   },
   "outputs": [],
   "source": [
    "# Define \"simple_lemmatize\"    \n",
    "def simple_lammatize(lists):\n",
    "    return [[wnl.lemmatize(word) for word in x] for x in lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Rc3Gl_v-tC4J"
   },
   "outputs": [],
   "source": [
    "# Apply the function on a few reviews\n",
    "sample_lammatize = simple_lammatize(data_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bFHnnVhtH6y"
   },
   "source": [
    "Checklist and Next Steps:\n",
    "\n",
    "- Check if the `simple_lemmatize` function is working as intended. Once verified, go ahead and apply it on the entire reviews column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JabvOHmqtdaT"
   },
   "outputs": [],
   "source": [
    "# Apply \"simple_lemmatize\" on all the reviews in the dataset\n",
    "data_lammatized = simple_lammatize(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Uem7LWP61xL1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['rock', 'destin', 'st', 'centuri', 'new', 'conan', 'go', 'make', 'splash', 'even', 'greater', 'arnold', 'schwarzenegg', 'jean', 'claud', 'van', 'damm', 'steven', 'segal'], ['gorgeous', 'elabor', 'continu', 'lord', 'ring', 'trilog', 'huge', 'column', 'word', 'cannot', 'adequ', 'describ', 'co', 'writer', 'director', 'peter', 'jackson', 'expand', 'vision', 'tolkien', 'middl', 'earth'], ['effect', 'tepid', 'biopic'], ['sometim', 'like', 'go', 'movi', 'fun', 'wasabi', 'good', 'place', 'start'], ['emerg', 'someth', 'rare', 'issu', 'movi', 'honest', 'keenli', 'observ', 'feel', 'like', 'one']]\n",
      "\n",
      "[['rock', 'destined', 'st', 'century', 'new', 'conan', 'going', 'make', 'splash', 'even', 'greater', 'arnold', 'schwarzenegger', 'jean', 'claud', 'van', 'damme', 'steven', 'segal'], ['gorgeously', 'elaborate', 'continuation', 'lord', 'ring', 'trilogy', 'huge', 'column', 'word', 'cannot', 'adequately', 'describe', 'co', 'writer', 'director', 'peter', 'jackson', 'expanded', 'vision', 'tolkien', 'middle', 'earth'], ['effective', 'tepid', 'biopic'], ['sometimes', 'like', 'go', 'movie', 'fun', 'wasabi', 'good', 'place', 'start'], ['emerges', 'something', 'rare', 'issue', 'movie', 'honest', 'keenly', 'observed', 'feel', 'like', 'one']]\n"
     ]
    }
   ],
   "source": [
    "# Review the dataset after using NLP techniques to pre-process it\n",
    "print(data_stemmed[:5])\n",
    "print()\n",
    "print(data_lammatized[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYq_Qen9RfWW"
   },
   "source": [
    "### Tf-Idf Data Preparation\n",
    "\n",
    "#### Guidelines\n",
    "\n",
    "- Perform a train_test split of the reviews data. You can choose a split of your choice, along with any random state.\n",
    "- Use the `TfidfVectorizer` object to create a n-gram model for both the train and validation reviews\n",
    "- For this assignment, we recommend using max_features as `500`, though you can tweak the parameters to creat your final data set\n",
    "- Also, ngram_range should be set to (1,2) \n",
    "- After `TfidfVectorizer` method has been initialized, use it to fit and transform the train data. Use the same tf-idf model to transform the validation data as well.\n",
    "- Check the final shape of train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QM7QVgFlTL20",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rock, destined, st, century, new, conan, goin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[gorgeously, elaborate, continuation, lord, ri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[effective, tepid, biopic]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sometimes, like, go, movie, fun, wasabi, good...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[emerges, something, rare, issue, movie, hones...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  labels\n",
       "0  [rock, destined, st, century, new, conan, goin...       1\n",
       "1  [gorgeously, elaborate, continuation, lord, ri...       1\n",
       "2                         [effective, tepid, biopic]       1\n",
       "3  [sometimes, like, go, movie, fun, wasabi, good...       1\n",
       "4  [emerges, something, rare, issue, movie, hones...       1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding labels and creating a new dataframe\n",
    "\n",
    "labels = df['Label'].replace({'pos': 1, 'neg': 0})\n",
    "review_data = pd.DataFrame({'reviews' : data_lammatized, 'labels' : labels})\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train-test split of the reviews data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(review_data['reviews'], review_data['labels'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting inputs into strings\n",
    "X_train_strings = [' '.join(tokens) for tokens in X_train]\n",
    "X_test_strings = [' '.join(tokens) for tokens in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GYx-_3b0Xbhh"
   },
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer object and use it to fit and transform the train set\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features = 500, stop_words = 'english', use_idf = True, ngram_range = (1, 2))\n",
    "\n",
    "Tfidf_train = tfidf_vectorizer.fit_transform(X_train_strings).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "l-l9AHlNXtFb"
   },
   "outputs": [],
   "source": [
    "# Using the same model, transform the validation set\n",
    "Tfidf_test = tfidf_vectorizer.fit_transform(X_test_strings).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BF002HERsGZ0",
    "outputId": "318ddefb-514e-4230-8c0e-e7fd7be457b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train : (8529, 500)\n",
      "Tfidf_test : (2133, 500)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the train and validation sets\n",
    "print('Tfidf_train :', Tfidf_train.shape)\n",
    "print('Tfidf_test :', Tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTqLAXHAX5Uk"
   },
   "source": [
    "### Label Encoding sentiments\n",
    "\n",
    "#### Guidelines\n",
    "- As you might have seen in the dataset, the sentiments are encoded as 'pos' and 'neg'\n",
    "- We need to convert these to 1 and 0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "pCsVY4sdsNyF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6690    0\n",
      "5284    1\n",
      "4645    1\n",
      "3597    1\n",
      "3821    1\n",
      "       ..\n",
      "2895    1\n",
      "7813    0\n",
      "905     1\n",
      "5192    1\n",
      "235     1\n",
      "Name: labels, Length: 8529, dtype: int64\n",
      "\n",
      "7895    0\n",
      "6722    0\n",
      "1305    1\n",
      "4543    1\n",
      "1185    1\n",
      "       ..\n",
      "2770    1\n",
      "4488    1\n",
      "1145    1\n",
      "7667    0\n",
      "9868    0\n",
      "Name: labels, Length: 2133, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the target variable to train and validation sets\n",
    "\n",
    "# Using LabelEncoder, convert 'pos' and 'neg' classes to '1' and '0' in the training data set output\n",
    "\n",
    "# Using LabelEncoder, convert 'pos' and 'neg' classes to '1' and '0' in the validation  data set output\n",
    "print(y_train)\n",
    "print()\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afHKKVtpRx5h"
   },
   "source": [
    "# Task II - Build a conventional supervised machine learning model\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "**Note** : The minimum requirement here is to build at least one conventional machine learning model. Though we recommend you try out multiple ML models and see which one is performing the best.\n",
    "\n",
    "Here's our suggested approach:\n",
    "\n",
    " - Train different classification models on the training data set and test its performance\n",
    "    - Logistic regression model\n",
    "    - Decision tree model\n",
    "    - kNN model\n",
    "    - Random forest classifier model\n",
    "    - Light gradient boosted tree classifier\n",
    " - Analyze the performance of all the models and select the one that performs with good accuracy and robustness\n",
    " - Perform hyperparameter tuning for the best model to further improve the model performance\n",
    " - Display the final model performance parameters like accuracy, confusion matrix, ROC and AUC.\n",
    "\n",
    " ### References\n",
    "\n",
    " - We strongly urge you to check the code that you learned in the Machine Learning course (You can refer to the Model Selection session for an overview of multiple ML models quickly).\n",
    " - Here's a list of documentations for different ML models that you can build here:\n",
    "  - [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) \n",
    "  - [Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "  - [kNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "  - [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "  - [LGBM ](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "u0owJrjCsX1o"
   },
   "outputs": [],
   "source": [
    "# scaling the training and test data\n",
    "scaler = StandardScaler()\n",
    "Tfidf_train = scaler.fit_transform(Tfidf_train)\n",
    "Tfidf_test = scaler.fit_transform(Tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining RMSE\n",
    "def rmse(y_train, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model on the testing set: 0.5260196905766527\n"
     ]
    }
   ],
   "source": [
    "# logictic regression model\n",
    "\n",
    "lr_best_model = LogisticRegression(penalty='none', solver='lbfgs', random_state=0,  max_iter=200)\n",
    "lr_best_model.fit(Tfidf_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the testing set\n",
    "accuracy_lr = lr_best_model.score(Tfidf_test, y_test)\n",
    "print(\"Accuracy of the best model on the testing set:\", accuracy_lr)\n",
    "\n",
    "# Calculating rmse value\n",
    "lr_train_rmse = rmse(y_train, lr_best_model.predict(Tfidf_train))\n",
    "lr_val_rmse = rmse(y_test, lr_best_model.predict(Tfidf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting confusing matrix\n",
    "plt.rcParams.update({'font.size': 14}) # To make the plot labels easier to read\n",
    "\n",
    "# Plot the confusion matrix for the logistic regression model\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(lr_best_model, Tfidf_test, y_test, cmap = plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree regressor\n",
    "tree_best = DecisionTreeClassifier(random_state = 0, max_depth = 50)\n",
    "tree_best.fit(Tfidf_train, y_train)\n",
    "\n",
    "# calculating rmse values\n",
    "tree_train_rmse = rmse(y_train, tree_best.predict(Tfidf_train))\n",
    "tree_test_rmse = rmse(y_test, tree_best.predict(Tfidf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum accuracy is obtained at k = 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# knn model\n",
    "\n",
    "kvalues = np.arange(1,31) # Parameter range\n",
    "\n",
    "test_acc=[]\n",
    "\n",
    "for k in kvalues:\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_clf.fit(Tfidf_train, y_train)\n",
    "    y_pred = knn_clf.predict(Tfidf_test)\n",
    "    test_acc.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "### Accuracy vs k\n",
    "plt.plot(kvalues,test_acc,marker='o')\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "print(\"The maximum accuracy is obtained at k = \" + str(np.argmax(test_acc)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf_best = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_clf_best.fit(Tfidf_train, y_train)\n",
    "\n",
    "# Calculating rmse value\n",
    "knn_train_rmse = rmse(y_train, knn_clf_best.predict(Tfidf_train))\n",
    "knn_test_rmse = rmse(y_test, knn_clf_best.predict(Tfidf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_model = RandomForestClassifier(class_weight = 'balanced', max_depth = 5, n_estimators = 200, random_state = 123)\n",
    "rf_best_model.fit(Tfidf_train, y_train)\n",
    "\n",
    "# Calculating rmse value\n",
    "rf_train_rmse = rmse(y_train, rf_best_model.predict(Tfidf_train))\n",
    "rf_test_rmse = rmse(y_test, rf_best_model.predict(Tfidf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier(class_weight = 'balanced', max_depth = 5, n_estimators = 200, random_state = 123)\n",
    "lgbm_model.fit(Tfidf_train, y_train)\n",
    "\n",
    "# Calculating rmse value\n",
    "lgbm_train_rmse = rmse(y_train, lgbm_model.predict(Tfidf_train))\n",
    "lgbm_test_rmse = rmse(y_test, lgbm_model.predict(Tfidf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating error measures for different models\n",
    "models = [lr_best_model, tree_best, knn_clf_best, rf_best_model, lgbm_model]\n",
    "y_preds = [model.predict(Tfidf_test) for model in models]\n",
    "accuracies = [accuracy_score(y_test, y_pred) for y_pred in y_preds]\n",
    "f1_scores = [f1_score(y_test, y_pred) for y_pred in y_preds]\n",
    "recall_values = [recall_score(y_test, y_pred) for y_pred in y_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>Tree</th>\n",
       "      <th>Knn</th>\n",
       "      <th>Rainforest</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracies</th>\n",
       "      <td>0.526020</td>\n",
       "      <td>0.496953</td>\n",
       "      <td>0.501641</td>\n",
       "      <td>0.502110</td>\n",
       "      <td>0.488983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Scores</th>\n",
       "      <td>0.511358</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.460680</td>\n",
       "      <td>0.594037</td>\n",
       "      <td>0.418977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Values</th>\n",
       "      <td>0.496248</td>\n",
       "      <td>0.173546</td>\n",
       "      <td>0.425891</td>\n",
       "      <td>0.728893</td>\n",
       "      <td>0.368668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Logistic      Tree       Knn  Rainforest      LGBM\n",
       "Accuracies     0.526020  0.496953  0.501641    0.502110  0.488983\n",
       "F1 Scores      0.511358  0.256410  0.460680    0.594037  0.418977\n",
       "Recall Values  0.496248  0.173546  0.425891    0.728893  0.368668"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for error measures\n",
    "\n",
    "pd.DataFrame([accuracies, f1_scores, recall_values], columns=['Logistic', 'Tree', 'Knn', 'Rainforest', 'LGBM'], \n",
    "              index = ['Accuracies', 'F1 Scores', 'Recall Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE Train</th>\n",
       "      <th>RMSE Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.522335</td>\n",
       "      <td>0.688462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tree</th>\n",
       "      <td>0.524240</td>\n",
       "      <td>0.709258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.133058</td>\n",
       "      <td>0.705946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rainforest</th>\n",
       "      <td>0.574908</td>\n",
       "      <td>0.705613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.524798</td>\n",
       "      <td>0.714855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RMSE Train  RMSE Validation\n",
       "Logistic      0.522335         0.688462\n",
       "Tree          0.524240         0.709258\n",
       "kNN           0.133058         0.705946\n",
       "Rainforest    0.574908         0.705613\n",
       "LGBM          0.524798         0.714855"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for rmse values\n",
    "pd.DataFrame([[lr_train_rmse, lr_val_rmse],[tree_train_rmse, tree_test_rmse], \n",
    "            [knn_train_rmse, knn_test_rmse], [rf_train_rmse, rf_test_rmse], [lgbm_train_rmse, lgbm_test_rmse]],\n",
    "            columns=['RMSE Train', 'RMSE Validation'], \n",
    "            index = ['Logistic', 'Tree', 'kNN', 'Rainforest', 'LGBM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC train = 0.813\n",
      "ROC AUC val = 0.499\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating ROC curve for Logistic model\n",
    "\n",
    "# Predict probabilities for the training set\n",
    "lgbm_probs_train = lgbm_model.predict_proba(Tfidf_train)\n",
    "\n",
    "# Retain probabilities for only positive outcomes\n",
    "lgbm_probs_train = lgbm_probs_train[:, 1]\n",
    "\n",
    "# Predict probabilities for the validation set and retain them for only positive outcomes\n",
    "lgbm_probs_test = lgbm_model.predict_proba(Tfidf_test)[:, 1]\n",
    "\n",
    "# Calculate ROC AUC scores for training and validation predictions\n",
    "lgbm_auc_train = roc_auc_score(y_train, lgbm_probs_train)\n",
    "lgbm_auc_val = roc_auc_score(y_test, lgbm_probs_test)\n",
    "\n",
    "# Print scores\n",
    "print('ROC AUC train = %.3f' % (lgbm_auc_train))\n",
    "print('ROC AUC val = %.3f' % (lgbm_auc_val))\n",
    "\n",
    "# Calculate 1-specificity and sensitivity values for training and validation predictions\n",
    "lgbm_1sp_train, lgbm_sen_train, _ = roc_curve(y_train, lgbm_probs_train)\n",
    "lgbm_1sp_test, lgbm_sen_test, _ = roc_curve(y_test, lgbm_probs_test)\n",
    "\n",
    "# Plot the ROC curve for the model\n",
    "plt.plot(lgbm_1sp_train, lgbm_sen_train, marker = '.', label = 'LGBM_train')\n",
    "plt.plot(lgbm_1sp_test, lgbm_sen_test, marker = '.', label = 'LGBM_test')\n",
    "plt.plot([0,1], [0,1], linestyle = '--') # Baseline\n",
    "\n",
    "# Set axis labels\n",
    "plt.xlabel('1-specificity')\n",
    "plt.ylabel('sensitivity')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate precision and recall for the validation predictions\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, lgbm_probs_test)\n",
    "\n",
    "# Create the precision-recall curve\n",
    "plt.plot(recall,precision)\n",
    "\n",
    "# Add axis labels to the plot\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykrcIdDiUeKv"
   },
   "source": [
    "# Task III - Build a deep learning model\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "For this task, you will perform the following steps:\n",
    "  - Convert the data set stored in as a sparse matrix to a sparse tensor for the Keras model\n",
    "    - A reference code is provided below\n",
    "  - Create a simple fully-connected feedforward neural network\n",
    "  - Fit the model on the training data set\n",
    "  - Test the accuracy of the model on the validation data set\n",
    "  - Show how the accuracy changes with every epoch during the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxgCf_GL66aD"
   },
   "source": [
    "#### Reference code for converting the sparse Tf-idf matrix to a sparse tensor\n",
    "\n",
    "Converting the sparse matrix of a dataset obtained from Tf-Idf vectorization to a sparse tensor.This is done as Keras runs on Tensorflow backend and a Keras model accepts a sparse tensor as input, not a sparse matrix.\n",
    "\n",
    "You can do the same easily using the `tf.SparseTensor` method([documentation](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor)) along with the `.tocoo()` method ([documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.tocoo.html))\n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "-  The .tocoo() method converts the tf-idf matrix to a coordinate format.\n",
    "-  the tf.SparseTensor() method takes the output of the .tocoo() method and creates a SparseTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8yoUM6y8p-F"
   },
   "source": [
    "A sample code has been provided here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Z8D81sk77YJw"
   },
   "outputs": [],
   "source": [
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZOln_R_76D9"
   },
   "source": [
    "After obtaining the sparse matrix from the above function, you have to do sparse reordering because tensorflow accepts input in row-major format. You can do the same using the `tf.sparse.reorder` method\n",
    "\n",
    "You can check out its documentation [here](https://www.tensorflow.org/api_docs/python/tf/sparse/reorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-FYYjieC73Yp"
   },
   "outputs": [],
   "source": [
    "## After converting the tf-idf data to a SparseTensor using the code snippet above, use the code below to do sparse reordering.\n",
    "##tf.sparse.reorder(X)\n",
    "## Here X is the sparse tensor output of the \"convert_sparse_matrix_to_sparse_tensor\" function\n",
    "\n",
    "# For the training dataset\n",
    "# Tfidf_train = coo_matrix(Tfidf_train).tocoo()\n",
    "\n",
    "# For the validation dataset\n",
    "# Tfidf_test = coo_matrix(Tfidf_test).tocoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB5s_Yva_sVr"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAfCv6eJADbD"
   },
   "source": [
    "## Building the Neural Network\n",
    "\n",
    "Now that you saw how to convert the data to the correct format, it's time to implement it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufzK_Es7CLSM"
   },
   "source": [
    "### Creating the sparse tensor input for both train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6LA6GmLu78Rz"
   },
   "outputs": [],
   "source": [
    "# Converting sparse matrix to sparse tensor to submit as input to the Keras model\n",
    "# Use the reference code that you learnt earlier\n",
    "# Perform both the steps for train and validation sets\n",
    "\n",
    "# For the training dataset\n",
    "#Tfidf_train = convert_sparse_matrix_to_sparse_tensor(Tfidf_train)\n",
    "#y_train = np.asarray(y_train)\n",
    "\n",
    "# For the validation dataset\n",
    "#Tfidf_test = convert_sparse_matrix_to_sparse_tensor(Tfidf_test)\n",
    "#y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZerR3HRBBG5"
   },
   "source": [
    "### Define the neural network function\n",
    "\n",
    "You can now go ahead and build the neural network. Here are a sample set of instructions that you may follow for this\n",
    "\n",
    "\n",
    "- Start by defining a function called `create_nn` with two parameters: activation_function and hidden1_neurons.\n",
    "\n",
    "- Inside the function, create a sparse input layer for a neural network using keras.Input(). Set the shape parameter to the correct value to indicate the input shape and `sparse=True` to specify that the input is a sparse tensor. Assign this input layer to a variable called `input`.\n",
    "\n",
    "- Create the first hidden layer of the neural network using layers.Dense(). Set the units parameter to hidden1_neurons (which has a default value of 256) and the activation parameter to activation_function. Pass the input layer as the input to this hidden layer. Assign this hidden layer to a variable called hidden1.\n",
    "\n",
    "- Create the second hidden layer of the neural network using layers.Dense(). Set the units parameter to 64 and the activation parameter to activation_function. Pass the hidden1 layer as the input to this hidden layer. Assign this hidden layer to a variable called hidden2.\n",
    "\n",
    "- Create the output layer of the neural network using layers.Dense(). Set the units parameter to 1 (since it has only one node). Pass the hidden2 layer as the input to this output layer. Assign this output layer to a variable called output.\n",
    "\n",
    "- Use keras.Model() to create the neural network model. Pass the input layer as the first argument and the output layer as the second argument. This function call will create and return the fully connected feedforward neural network.\n",
    "Finally, add a return statement to return the created model.\n",
    "\n",
    "*Remember to import the necessary libraries, such as tensorflow and keras, before running the code*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "r7K_6w5161bs"
   },
   "outputs": [],
   "source": [
    "# Defining a fully-connected feedforward neural network\n",
    "# You may write the code using the instructions shared above or follow your own approach\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_nn(activation_function = 'sigmoid', hidden1_neurons = 256):\n",
    "    \n",
    "    input_layer = keras.Input(shape = (500, ), sparse = True, name = 'tfidf_max_features')\n",
    "    \n",
    "    hidden1 = layers.Dense(hidden1_neurons, activation = activation_function)(input_layer)\n",
    "    hidden2 = layers.Dense(units = 64, activation = activation_function)(hidden1)\n",
    "    \n",
    "    output_layer = layers.Dense(units = 1)(hidden2)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBh5DQXkDQr7"
   },
   "source": [
    "Build the FCFNN instance\n",
    "\n",
    "- Create an instance of the fully connected feedforward neural network.\n",
    "- Set the learning rate value to 0.01. This value will be used when compiling the neural network.\n",
    "- Compile the neural network using the compile() method of nn1. \n",
    "- **Important** - Set the loss parameter to `'binary_crossentropy'`, since the output layer has only 1 node. \n",
    "- Set the metrics parameter to ['accuracy'] to track the accuracy during training. \n",
    "- For the optimizer parameter, create an instance of the RMSprop optimizer \n",
    "- Call the summary() method on the instance to print a summary of the neural network architecture.\n",
    "\n",
    "*Remember to import the necessary libraries, such as tensorflow, keras, and RMSprop, before running the code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "zhFTIqPT6-2M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tfidf_max_features (InputLa  [(None, 500)]            0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               128256    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144,769\n",
      "Trainable params: 144,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Build the FCFNN instance using the instructions shared above or you can follow your own approach\n",
    "nn1 = create_nn()\n",
    "\n",
    "nn1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOxo-mlSELHE"
   },
   "source": [
    "Build a simple FCFNN model\n",
    "\n",
    "- Train the neural network model on the dataset using the fit() method of the FCFNN instance you built previously\n",
    "- Pass the training data and the validation data\n",
    "- Set the epochs parameter to 10 to specify the number of training epochs.\n",
    "- The fit() method will return a history object that contains information about the training process. Assign this object to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "m-BlEoIC7kFx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "267/267 [==============================] - 2s 5ms/step - loss: 0.9833 - accuracy: 0.6212 - val_loss: 1.2053 - val_accuracy: 0.4970\n",
      "Epoch 2/10\n",
      "267/267 [==============================] - 1s 3ms/step - loss: 0.7522 - accuracy: 0.6691 - val_loss: 0.8653 - val_accuracy: 0.5148\n",
      "Epoch 3/10\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 0.6406 - accuracy: 0.6934 - val_loss: 1.8809 - val_accuracy: 0.4885\n",
      "Epoch 4/10\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 0.6338 - accuracy: 0.7038 - val_loss: 1.5764 - val_accuracy: 0.5091\n",
      "Epoch 5/10\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 0.6187 - accuracy: 0.7079 - val_loss: 1.4214 - val_accuracy: 0.5045\n",
      "Epoch 6/10\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 0.5990 - accuracy: 0.7158 - val_loss: 1.6862 - val_accuracy: 0.5082\n",
      "Epoch 7/10\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 0.5907 - accuracy: 0.7190 - val_loss: 1.2622 - val_accuracy: 0.5096\n",
      "Epoch 8/10\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.5614 - accuracy: 0.7304 - val_loss: 1.3182 - val_accuracy: 0.5096\n",
      "Epoch 9/10\n",
      "267/267 [==============================] - 1s 4ms/step - loss: 0.5441 - accuracy: 0.7376 - val_loss: 1.1648 - val_accuracy: 0.5054\n",
      "Epoch 10/10\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7435 - val_loss: 1.3278 - val_accuracy: 0.5030\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network model on the dataset\n",
    "nn1_history = nn1.fit(Tfidf_train, y_train, validation_data=(Tfidf_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWH1D9IkFPtI"
   },
   "source": [
    "Convert Neural Network History to a DataFrame and Plot it\n",
    " \n",
    "- Create a DataFrame containing the training history of the neural network.\n",
    "- Add a new column to the DataFrame called 'epoch' that represents the epochs of the training process.\n",
    "- After that plot the training and validation accuracies as functions of epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "-wDL8mOz7i_g"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.983332</td>\n",
       "      <td>0.621175</td>\n",
       "      <td>1.205318</td>\n",
       "      <td>0.496953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.752198</td>\n",
       "      <td>0.669129</td>\n",
       "      <td>0.865322</td>\n",
       "      <td>0.514768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.640571</td>\n",
       "      <td>0.693399</td>\n",
       "      <td>1.880929</td>\n",
       "      <td>0.488514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.633838</td>\n",
       "      <td>0.703834</td>\n",
       "      <td>1.576373</td>\n",
       "      <td>0.509142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.618698</td>\n",
       "      <td>0.707938</td>\n",
       "      <td>1.421442</td>\n",
       "      <td>0.504454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.599040</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>1.686196</td>\n",
       "      <td>0.508204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.590728</td>\n",
       "      <td>0.718959</td>\n",
       "      <td>1.262161</td>\n",
       "      <td>0.509611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.561360</td>\n",
       "      <td>0.730449</td>\n",
       "      <td>1.318211</td>\n",
       "      <td>0.509611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.544133</td>\n",
       "      <td>0.737601</td>\n",
       "      <td>1.164844</td>\n",
       "      <td>0.505391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.532216</td>\n",
       "      <td>0.743463</td>\n",
       "      <td>1.327820</td>\n",
       "      <td>0.503047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  accuracy  val_loss  val_accuracy\n",
       "epoch                                            \n",
       "1      0.983332  0.621175  1.205318      0.496953\n",
       "2      0.752198  0.669129  0.865322      0.514768\n",
       "3      0.640571  0.693399  1.880929      0.488514\n",
       "4      0.633838  0.703834  1.576373      0.509142\n",
       "5      0.618698  0.707938  1.421442      0.504454\n",
       "6      0.599040  0.715793  1.686196      0.508204\n",
       "7      0.590728  0.718959  1.262161      0.509611\n",
       "8      0.561360  0.730449  1.318211      0.509611\n",
       "9      0.544133  0.737601  1.164844      0.505391\n",
       "10     0.532216  0.743463  1.327820      0.503047"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the neural network history object into a data frame to view its specifics\n",
    "hist = pd.DataFrame(nn1_history.history)\n",
    "hist['epoch'] = nn1_history.epoch\n",
    "hist['epoch'] = hist['epoch'].apply(lambda x: x + 1)\n",
    "hist.set_index('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "OU3nlVwg7zyq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy as a function of Epoch')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the training and validation accuracies as functions of epoch\n",
    "plt.figure(figsize=(14,4))\n",
    "sns.lineplot(data=hist, x='epoch', y='accuracy', color='red', label='Training')\n",
    "sns.lineplot(data=hist, x='epoch', y='val_accuracy', color='blue', label='validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy as a function of Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBUZvkoIF6o1"
   },
   "source": [
    "Check the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "9n2ZYiZ47sS-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 2ms/step - loss: 1.3278 - accuracy: 0.5030\n",
      "The loss value of the model on the validation data is 1.3278199434280396\n",
      "The accuracy of the model on the validation data is 0.5030473470687866\n"
     ]
    }
   ],
   "source": [
    "# Compute the final accuracy of the model on the validation data set using the 'evaluate()' method\n",
    "performance_test = nn1.evaluate(Tfidf_test, y_test)\n",
    "\n",
    "print('The loss value of the model on the validation data is {}'.format(performance_test[0]))\n",
    "print('The accuracy of the model on the validation data is {}'.format(performance_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06-YE5T1F_7Q"
   },
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Now that you have built a simple FCFNN model, it's time to optimize the model using hyperparameter tuning.\n",
    "\n",
    "#### Guidelines\n",
    "Here are a few guidelines on how to do the same:\n",
    "\n",
    "- Choose multiple activation functions such as 'sigmoid' and 'relu'.\n",
    "\n",
    "- Choose multiple values for hidden neurons such as 128 and 256.\n",
    "\n",
    "- Create an empty DataFrame to store the performance results of the nn models that we plan to build\n",
    "\n",
    "- Run a nested loop across all the different activation functions in activation_function_list, and over the number of neurons in hidden1_neurons_list. and create a neural network for each instance.\n",
    "\n",
    "- Complie the model similar to how built the simple FCFNN model. Use the different parameters accordingly.\n",
    "\n",
    "- Create a DataFrame with the relevant information (activation function, number of neurons, train accuracy, and validation accuracy) for the current model.\n",
    "\n",
    "- Concatenate the same with the previous empty DataFrame that we created. After the nested loop finishes, the DataFrame will contain the performance results for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "U-q9QKDjCz76",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 7.8228 - accuracy: 0.4928\n",
      "[CV 1/2] END activation_function=sigmoid, hidden1_neurons=128;, score=0.493 total time=   5.3s\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 2.5047 - accuracy: 0.4928\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7325 - accuracy: 0.5142\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7095 - accuracy: 0.5233\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6949 - accuracy: 0.5379\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6844 - accuracy: 0.5505\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6763 - accuracy: 0.5698\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6697 - accuracy: 0.5871\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6638 - accuracy: 0.5981\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6585 - accuracy: 0.6070\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6535 - accuracy: 0.6192\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6488 - accuracy: 0.6300\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6441 - accuracy: 0.6368\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6396 - accuracy: 0.6415\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6352 - accuracy: 0.6492\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6308 - accuracy: 0.6586\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6265 - accuracy: 0.6640\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6222 - accuracy: 0.6729\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6180 - accuracy: 0.6760\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6138 - accuracy: 0.6828\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6096 - accuracy: 0.6853\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6056 - accuracy: 0.6898\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6015 - accuracy: 0.6921\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5975 - accuracy: 0.6926\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5935 - accuracy: 0.6961\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5896 - accuracy: 0.6994\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5857 - accuracy: 0.7008\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5818 - accuracy: 0.7032\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5780 - accuracy: 0.7046\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5742 - accuracy: 0.7086\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5704 - accuracy: 0.7093\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5667 - accuracy: 0.7090\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5631 - accuracy: 0.7175\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5595 - accuracy: 0.7208\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5559 - accuracy: 0.7217\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5524 - accuracy: 0.7229\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5490 - accuracy: 0.7240\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5457 - accuracy: 0.7259\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5424 - accuracy: 0.7271\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5392 - accuracy: 0.7275\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5361 - accuracy: 0.7285\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5331 - accuracy: 0.7306\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5301 - accuracy: 0.7311\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5272 - accuracy: 0.7308\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5244 - accuracy: 0.7320\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5217 - accuracy: 0.7325\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5191 - accuracy: 0.7343\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5166 - accuracy: 0.7341\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5141 - accuracy: 0.7346\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5118 - accuracy: 0.7367\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5095 - accuracy: 0.7369\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5074 - accuracy: 0.7376\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5054 - accuracy: 0.7383\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5038 - accuracy: 0.7383\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5051 - accuracy: 0.7261\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5472 - accuracy: 0.7247\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8419 - accuracy: 0.6506\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9444 - accuracy: 0.6366\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5175 - accuracy: 0.7224\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4986 - accuracy: 0.7411\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4965 - accuracy: 0.7407\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4951 - accuracy: 0.7411\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4936 - accuracy: 0.7414\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4922 - accuracy: 0.7430\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4909 - accuracy: 0.7430\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4895 - accuracy: 0.7440\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4882 - accuracy: 0.7435\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4870 - accuracy: 0.7428\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4857 - accuracy: 0.7423\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4845 - accuracy: 0.7426\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4833 - accuracy: 0.7430\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4821 - accuracy: 0.7426\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4809 - accuracy: 0.7435\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4798 - accuracy: 0.7444\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4786 - accuracy: 0.7442\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4775 - accuracy: 0.7458\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4763 - accuracy: 0.7444\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4752 - accuracy: 0.7463\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4742 - accuracy: 0.7491\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4734 - accuracy: 0.7477\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4736 - accuracy: 0.7503\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4777 - accuracy: 0.7468\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5101 - accuracy: 0.7402\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7055 - accuracy: 0.6917\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8355 - accuracy: 0.6811\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7378 - accuracy: 0.6743\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4719 - accuracy: 0.7529\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4703 - accuracy: 0.7522\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4693 - accuracy: 0.7512\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4684 - accuracy: 0.7515\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4676 - accuracy: 0.7510\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4667 - accuracy: 0.7510\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4659 - accuracy: 0.7515\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4650 - accuracy: 0.7515\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4642 - accuracy: 0.7529\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4634 - accuracy: 0.7526\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4625 - accuracy: 0.7533\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4617 - accuracy: 0.7538\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4609 - accuracy: 0.7536\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4600 - accuracy: 0.7540\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4592 - accuracy: 0.7538\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4583 - accuracy: 0.7543\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4575 - accuracy: 0.7559\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4566 - accuracy: 0.7550\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4557 - accuracy: 0.7564\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4549 - accuracy: 0.7566\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4540 - accuracy: 0.7573\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4532 - accuracy: 0.7555\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4524 - accuracy: 0.7585\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4519 - accuracy: 0.7569\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4520 - accuracy: 0.7623\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4540 - accuracy: 0.7566\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4628 - accuracy: 0.7580\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5052 - accuracy: 0.7355\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7606 - accuracy: 0.7008\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6386 - accuracy: 0.6982\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8229 - accuracy: 0.6870\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4721 - accuracy: 0.7508\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4519 - accuracy: 0.7623\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4494 - accuracy: 0.7634\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4483 - accuracy: 0.7651\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4473 - accuracy: 0.7658\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4465 - accuracy: 0.7660\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4456 - accuracy: 0.7655\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4448 - accuracy: 0.7653\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4440 - accuracy: 0.7660\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4432 - accuracy: 0.7653\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4424 - accuracy: 0.7655\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4416 - accuracy: 0.7660\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4408 - accuracy: 0.7660\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4400 - accuracy: 0.7655\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4392 - accuracy: 0.7655\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4384 - accuracy: 0.7662\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4376 - accuracy: 0.7660\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4367 - accuracy: 0.7665\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4359 - accuracy: 0.7660\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4351 - accuracy: 0.7679\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4342 - accuracy: 0.7676\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4333 - accuracy: 0.7686\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4325 - accuracy: 0.7691\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4316 - accuracy: 0.7691\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4307 - accuracy: 0.7714\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4299 - accuracy: 0.7700\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4292 - accuracy: 0.7735\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4288 - accuracy: 0.7709\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4295 - accuracy: 0.7749\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4324 - accuracy: 0.7691\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4429 - accuracy: 0.7700\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4843 - accuracy: 0.7465\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5417 - accuracy: 0.7447\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8559 - accuracy: 0.6846\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5186 - accuracy: 0.7510\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4269 - accuracy: 0.7744\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4248 - accuracy: 0.7770\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4237 - accuracy: 0.7775\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4228 - accuracy: 0.7780\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4219 - accuracy: 0.7796\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4211 - accuracy: 0.7794\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4202 - accuracy: 0.7801\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4194 - accuracy: 0.7812\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4186 - accuracy: 0.7805\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4177 - accuracy: 0.7810\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4169 - accuracy: 0.7815\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4161 - accuracy: 0.7822\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4152 - accuracy: 0.7826\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4143 - accuracy: 0.7834\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4135 - accuracy: 0.7838\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4126 - accuracy: 0.7862\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4117 - accuracy: 0.7866\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4108 - accuracy: 0.7871\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4098 - accuracy: 0.7878\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4089 - accuracy: 0.7883\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4080 - accuracy: 0.7885\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4071 - accuracy: 0.7885\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4063 - accuracy: 0.7885\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4056 - accuracy: 0.7859\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4054 - accuracy: 0.7894\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4064 - accuracy: 0.7850\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4107 - accuracy: 0.7892\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4237 - accuracy: 0.7768\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4564 - accuracy: 0.7747\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6317 - accuracy: 0.7254\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4983 - accuracy: 0.7601\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4149 - accuracy: 0.7815\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3984 - accuracy: 0.8005\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3970 - accuracy: 0.7995\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3958 - accuracy: 0.8005\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3946 - accuracy: 0.8009\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3935 - accuracy: 0.8021\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3924 - accuracy: 0.8023\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3913 - accuracy: 0.8042\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3902 - accuracy: 0.8040\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3891 - accuracy: 0.8049\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3880 - accuracy: 0.8049\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3868 - accuracy: 0.8070\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3857 - accuracy: 0.8061\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3846 - accuracy: 0.8094\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3835 - accuracy: 0.8045\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3827 - accuracy: 0.8063\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3827 - accuracy: 0.8019\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3850 - accuracy: 0.8080\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.1960 - accuracy: 0.6599\n",
      "[CV 2/2] END activation_function=sigmoid, hidden1_neurons=128;, score=0.660 total time=   4.9s\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.6039 - accuracy: 0.5070\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 7.8228 - accuracy: 0.4928\n",
      "[CV 1/2] END activation_function=sigmoid, hidden1_neurons=256;, score=0.493 total time=   6.3s\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.5529 - accuracy: 0.5072\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.0403 - accuracy: 0.4928\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7477 - accuracy: 0.5313\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6890 - accuracy: 0.5606\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6711 - accuracy: 0.5794\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6607 - accuracy: 0.6005\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6521 - accuracy: 0.6185\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6442 - accuracy: 0.6284\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6368 - accuracy: 0.6368\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6297 - accuracy: 0.6471\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6228 - accuracy: 0.6539\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6162 - accuracy: 0.6600\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6099 - accuracy: 0.6685\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6037 - accuracy: 0.6760\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5977 - accuracy: 0.6804\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5919 - accuracy: 0.6868\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5863 - accuracy: 0.6893\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5809 - accuracy: 0.6950\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5757 - accuracy: 0.6994\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5706 - accuracy: 0.7001\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5657 - accuracy: 0.7032\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5610 - accuracy: 0.7064\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5565 - accuracy: 0.7072\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5522 - accuracy: 0.7097\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5482 - accuracy: 0.7104\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5443 - accuracy: 0.7130\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5406 - accuracy: 0.7147\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5372 - accuracy: 0.7182\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5338 - accuracy: 0.7210\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5307 - accuracy: 0.7236\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5277 - accuracy: 0.7257\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5249 - accuracy: 0.7266\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5223 - accuracy: 0.7266\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5198 - accuracy: 0.7280\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5174 - accuracy: 0.7273\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5151 - accuracy: 0.7287\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5129 - accuracy: 0.7299\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5108 - accuracy: 0.7320\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5088 - accuracy: 0.7304\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5069 - accuracy: 0.7351\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5055 - accuracy: 0.7308\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5069 - accuracy: 0.7348\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5591 - accuracy: 0.7041\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.8533 - accuracy: 0.5334\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9411 - accuracy: 0.5857\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5680 - accuracy: 0.6014\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6785 - accuracy: 0.5970\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5536 - accuracy: 0.7170\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5155 - accuracy: 0.7332\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5081 - accuracy: 0.7447\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5063 - accuracy: 0.7449\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5052 - accuracy: 0.7458\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5041 - accuracy: 0.7472\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5031 - accuracy: 0.7479\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5021 - accuracy: 0.7475\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5012 - accuracy: 0.7489\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5002 - accuracy: 0.7489\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4993 - accuracy: 0.7491\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4984 - accuracy: 0.7496\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4975 - accuracy: 0.7498\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4966 - accuracy: 0.7503\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4957 - accuracy: 0.7503\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4948 - accuracy: 0.7501\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4939 - accuracy: 0.7515\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4930 - accuracy: 0.7515\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4921 - accuracy: 0.7526\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4912 - accuracy: 0.7526\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4903 - accuracy: 0.7533\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4894 - accuracy: 0.7536\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4885 - accuracy: 0.7531\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4876 - accuracy: 0.7522\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4867 - accuracy: 0.7515\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4858 - accuracy: 0.7515\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4849 - accuracy: 0.7515\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4840 - accuracy: 0.7512\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4831 - accuracy: 0.7503\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4822 - accuracy: 0.7512\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4813 - accuracy: 0.7505\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4805 - accuracy: 0.7533\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4798 - accuracy: 0.7498\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4797 - accuracy: 0.7533\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4815 - accuracy: 0.7479\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4927 - accuracy: 0.7531\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7838 - accuracy: 0.6734\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.4408 - accuracy: 0.5301\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1056 - accuracy: 0.6408\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4910 - accuracy: 0.7468\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4846 - accuracy: 0.7440\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4829 - accuracy: 0.7482\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4816 - accuracy: 0.7465\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4806 - accuracy: 0.7470\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4796 - accuracy: 0.7475\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4786 - accuracy: 0.7468\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4777 - accuracy: 0.7463\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4768 - accuracy: 0.7454\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4759 - accuracy: 0.7470\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4751 - accuracy: 0.7482\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4743 - accuracy: 0.7482\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4735 - accuracy: 0.7489\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4727 - accuracy: 0.7491\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4719 - accuracy: 0.7491\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4711 - accuracy: 0.7496\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4703 - accuracy: 0.7487\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4695 - accuracy: 0.7494\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4688 - accuracy: 0.7503\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4680 - accuracy: 0.7512\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4672 - accuracy: 0.7526\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4664 - accuracy: 0.7536\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4657 - accuracy: 0.7522\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4650 - accuracy: 0.7547\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4644 - accuracy: 0.7536\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4642 - accuracy: 0.7538\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4649 - accuracy: 0.7529\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4682 - accuracy: 0.7601\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4844 - accuracy: 0.7383\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5912 - accuracy: 0.7329\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0507 - accuracy: 0.5876\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2952 - accuracy: 0.5937\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7107 - accuracy: 0.6016\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6247 - accuracy: 0.7097\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4739 - accuracy: 0.7522\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4691 - accuracy: 0.7644\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4675 - accuracy: 0.7625\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4666 - accuracy: 0.7623\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4659 - accuracy: 0.7637\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4653 - accuracy: 0.7634\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4648 - accuracy: 0.7641\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4642 - accuracy: 0.7648\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4637 - accuracy: 0.7653\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4632 - accuracy: 0.7662\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4626 - accuracy: 0.7653\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4621 - accuracy: 0.7653\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4616 - accuracy: 0.7655\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4610 - accuracy: 0.7669\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4605 - accuracy: 0.7674\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4599 - accuracy: 0.7674\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4594 - accuracy: 0.7681\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4588 - accuracy: 0.7686\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4583 - accuracy: 0.7688\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4577 - accuracy: 0.7683\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4571 - accuracy: 0.7679\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4566 - accuracy: 0.7686\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4560 - accuracy: 0.7679\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4554 - accuracy: 0.7679\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4548 - accuracy: 0.7683\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4542 - accuracy: 0.7688\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4536 - accuracy: 0.7683\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4529 - accuracy: 0.7686\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4523 - accuracy: 0.7683\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4517 - accuracy: 0.7688\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4510 - accuracy: 0.7688\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4503 - accuracy: 0.7688\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4497 - accuracy: 0.7707\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4490 - accuracy: 0.7695\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4484 - accuracy: 0.7700\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4478 - accuracy: 0.7702\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4474 - accuracy: 0.7686\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4473 - accuracy: 0.7716\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4480 - accuracy: 0.7655\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4515 - accuracy: 0.7719\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4665 - accuracy: 0.7503\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5426 - accuracy: 0.7484\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9421 - accuracy: 0.6652\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8537 - accuracy: 0.5325\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9917 - accuracy: 0.6225\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2531 - accuracy: 0.6898\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6714 - accuracy: 0.7402\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5198 - accuracy: 0.7540\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4843 - accuracy: 0.7615\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4692 - accuracy: 0.7653\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4591 - accuracy: 0.7705\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4549 - accuracy: 0.7702\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4525 - accuracy: 0.7698\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4520 - accuracy: 0.7705\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4498 - accuracy: 0.7700\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4502 - accuracy: 0.7644\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4484 - accuracy: 0.7679\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4475 - accuracy: 0.7686\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4469 - accuracy: 0.7691\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4464 - accuracy: 0.7686\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4459 - accuracy: 0.7683\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4455 - accuracy: 0.7676\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4451 - accuracy: 0.7681\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4447 - accuracy: 0.7691\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4442 - accuracy: 0.7693\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4438 - accuracy: 0.7700\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4433 - accuracy: 0.7700\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4429 - accuracy: 0.7695\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4424 - accuracy: 0.7702\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4419 - accuracy: 0.7700\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4414 - accuracy: 0.7707\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4410 - accuracy: 0.7714\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4405 - accuracy: 0.7719\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4399 - accuracy: 0.7726\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4394 - accuracy: 0.7728\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4389 - accuracy: 0.7733\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4384 - accuracy: 0.7735\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4378 - accuracy: 0.7728\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4373 - accuracy: 0.7730\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4367 - accuracy: 0.7733\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0112 - accuracy: 0.6670\n",
      "[CV 2/2] END activation_function=sigmoid, hidden1_neurons=256;, score=0.667 total time=   6.9s\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 4.2990 - accuracy: 0.5070\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.4754 - accuracy: 0.5223\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.0266 - accuracy: 0.5835\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.1114 - accuracy: 0.6086\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.7748 - accuracy: 0.6241\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3105 - accuracy: 0.6581\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9887 - accuracy: 0.6841\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8727 - accuracy: 0.6888\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8084 - accuracy: 0.7038\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7730 - accuracy: 0.7134\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7492 - accuracy: 0.7235\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7179 - accuracy: 0.7308\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6769 - accuracy: 0.7439\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.6021 - accuracy: 0.7530\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5341 - accuracy: 0.7538\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.6896 - accuracy: 0.7080\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4584 - accuracy: 0.7812\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4180 - accuracy: 0.7920\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3913 - accuracy: 0.8014\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3032 - accuracy: 0.7995\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3902 - accuracy: 0.7509\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2279 - accuracy: 0.8147\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1763 - accuracy: 0.8152\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1448 - accuracy: 0.8246\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1315 - accuracy: 0.8297\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1222 - accuracy: 0.8344\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1116 - accuracy: 0.8403\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1004 - accuracy: 0.8433\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0922 - accuracy: 0.8487\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0826 - accuracy: 0.8511\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0752 - accuracy: 0.8551\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0688 - accuracy: 0.8583\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0630 - accuracy: 0.8635\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0579 - accuracy: 0.8656\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0534 - accuracy: 0.8696\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0415 - accuracy: 0.8738\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0299 - accuracy: 0.8755\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0179 - accuracy: 0.8783\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0115 - accuracy: 0.8816\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0050 - accuracy: 0.8827\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9999 - accuracy: 0.8865\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9952 - accuracy: 0.8841\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9786 - accuracy: 0.8914\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9688 - accuracy: 0.8874\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9595 - accuracy: 0.8921\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9505 - accuracy: 0.8919\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9461 - accuracy: 0.8917\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9168 - accuracy: 0.8874\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8914 - accuracy: 0.8947\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8701 - accuracy: 0.8942\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8427 - accuracy: 0.9041\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8379 - accuracy: 0.9043\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8363 - accuracy: 0.9050\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8380 - accuracy: 0.9034\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8443 - accuracy: 0.8999\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8169 - accuracy: 0.9088\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8115 - accuracy: 0.9085\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8104 - accuracy: 0.9104\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8195 - accuracy: 0.9038\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8009 - accuracy: 0.9121\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7967 - accuracy: 0.9125\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7950 - accuracy: 0.9132\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7976 - accuracy: 0.9111\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7875 - accuracy: 0.9130\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7765 - accuracy: 0.9090\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7566 - accuracy: 0.9057\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7820 - accuracy: 0.8968\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8985 - accuracy: 0.8635\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7132 - accuracy: 0.9137\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7834 - accuracy: 0.8895\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6742 - accuracy: 0.9186\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6644 - accuracy: 0.9203\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6603 - accuracy: 0.9207\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6573 - accuracy: 0.9221\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6548 - accuracy: 0.9238\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6526 - accuracy: 0.9247\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6482 - accuracy: 0.9252\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6457 - accuracy: 0.9261\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6443 - accuracy: 0.9261\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6436 - accuracy: 0.9266\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6436 - accuracy: 0.9257\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6429 - accuracy: 0.9259\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6432 - accuracy: 0.9266\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6396 - accuracy: 0.9264\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6352 - accuracy: 0.9278\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6332 - accuracy: 0.9287\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6318 - accuracy: 0.9289\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6307 - accuracy: 0.9292\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6299 - accuracy: 0.9294\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6297 - accuracy: 0.9287\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6312 - accuracy: 0.9296\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6344 - accuracy: 0.9282\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6821 - accuracy: 0.9118\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6590 - accuracy: 0.9200\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6410 - accuracy: 0.9179\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6089 - accuracy: 0.9287\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5849 - accuracy: 0.9303\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5774 - accuracy: 0.9334\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5752 - accuracy: 0.9336\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5739 - accuracy: 0.9343\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5730 - accuracy: 0.9346\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5723 - accuracy: 0.9343\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5718 - accuracy: 0.9343\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5711 - accuracy: 0.9346\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5709 - accuracy: 0.9346\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5706 - accuracy: 0.9348\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5710 - accuracy: 0.9341\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5717 - accuracy: 0.9343\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5749 - accuracy: 0.9327\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5815 - accuracy: 0.9322\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6005 - accuracy: 0.9264\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6547 - accuracy: 0.9196\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5904 - accuracy: 0.9259\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5865 - accuracy: 0.9299\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5544 - accuracy: 0.9311\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5482 - accuracy: 0.9364\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5464 - accuracy: 0.9367\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5455 - accuracy: 0.9369\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5448 - accuracy: 0.9369\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5441 - accuracy: 0.9371\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5437 - accuracy: 0.9374\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5434 - accuracy: 0.9371\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5432 - accuracy: 0.9371\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5429 - accuracy: 0.9371\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5428 - accuracy: 0.9376\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5426 - accuracy: 0.9376\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5425 - accuracy: 0.9376\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5425 - accuracy: 0.9376\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5427 - accuracy: 0.9374\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5433 - accuracy: 0.9369\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5443 - accuracy: 0.9367\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5474 - accuracy: 0.9360\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5586 - accuracy: 0.9306\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6996 - accuracy: 0.9167\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6070 - accuracy: 0.9273\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6044 - accuracy: 0.9275\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5633 - accuracy: 0.9306\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5250 - accuracy: 0.9364\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5184 - accuracy: 0.9364\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5157 - accuracy: 0.9383\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5138 - accuracy: 0.9388\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5131 - accuracy: 0.9388\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5125 - accuracy: 0.9390\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5121 - accuracy: 0.9393\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5118 - accuracy: 0.9393\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5115 - accuracy: 0.9395\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5112 - accuracy: 0.9397\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5110 - accuracy: 0.9395\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5108 - accuracy: 0.9397\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5106 - accuracy: 0.9400\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5105 - accuracy: 0.9400\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5104 - accuracy: 0.9397\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5104 - accuracy: 0.9400\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5105 - accuracy: 0.9402\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5106 - accuracy: 0.9402\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5109 - accuracy: 0.9402\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5115 - accuracy: 0.9397\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5122 - accuracy: 0.9400\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5138 - accuracy: 0.9376\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5177 - accuracy: 0.9381\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5575 - accuracy: 0.9287\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7672 - accuracy: 0.9092\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5563 - accuracy: 0.9315\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5087 - accuracy: 0.9367\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4945 - accuracy: 0.9386\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4920 - accuracy: 0.9393\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4911 - accuracy: 0.9393\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4904 - accuracy: 0.9395\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4899 - accuracy: 0.9395\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4895 - accuracy: 0.9397\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4892 - accuracy: 0.9400\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4890 - accuracy: 0.9407\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4887 - accuracy: 0.9407\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4885 - accuracy: 0.9407\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4883 - accuracy: 0.9409\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4882 - accuracy: 0.9409\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4880 - accuracy: 0.9409\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4878 - accuracy: 0.9409\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4877 - accuracy: 0.9409\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4877 - accuracy: 0.9407\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4877 - accuracy: 0.9416\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4876 - accuracy: 0.9407\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4875 - accuracy: 0.9416\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4875 - accuracy: 0.9416\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4875 - accuracy: 0.9411\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4874 - accuracy: 0.9418\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4873 - accuracy: 0.9411\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4872 - accuracy: 0.9418\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4871 - accuracy: 0.9411\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4847 - accuracy: 0.9418\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4847 - accuracy: 0.9418\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4862 - accuracy: 0.9411\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4822 - accuracy: 0.9390\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6710 - accuracy: 0.9198\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7217 - accuracy: 0.8942\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6343 - accuracy: 0.9299\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5118 - accuracy: 0.9376\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4817 - accuracy: 0.9395\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4703 - accuracy: 0.9402\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4627 - accuracy: 0.9409\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 3.0729 - accuracy: 0.6246\n",
      "[CV 1/2] END activation_function=relu, hidden1_neurons=128;, score=0.625 total time=   5.3s\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 4.4473 - accuracy: 0.5177\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.7520 - accuracy: 0.5149\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.5228 - accuracy: 0.5819\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.9853 - accuracy: 0.6171\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.6741 - accuracy: 0.6134\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1352 - accuracy: 0.6617\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8313 - accuracy: 0.6961\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7050 - accuracy: 0.6971\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8200 - accuracy: 0.6994\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8283 - accuracy: 0.6746\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4765 - accuracy: 0.7489\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4536 - accuracy: 0.7383\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3472 - accuracy: 0.7632\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2980 - accuracy: 0.7726\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2676 - accuracy: 0.7831\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2376 - accuracy: 0.7913\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1838 - accuracy: 0.7869\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3140 - accuracy: 0.7243\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1137 - accuracy: 0.8124\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0240 - accuracy: 0.8178\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9951 - accuracy: 0.7784\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9455 - accuracy: 0.8300\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9087 - accuracy: 0.8349\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8691 - accuracy: 0.8359\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8581 - accuracy: 0.8385\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8388 - accuracy: 0.8481\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8263 - accuracy: 0.8528\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8173 - accuracy: 0.8593\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8101 - accuracy: 0.8633\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8033 - accuracy: 0.8675\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7968 - accuracy: 0.8713\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7906 - accuracy: 0.8732\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7848 - accuracy: 0.8767\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7746 - accuracy: 0.8769\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7666 - accuracy: 0.8809\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7607 - accuracy: 0.8832\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7507 - accuracy: 0.8849\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7442 - accuracy: 0.8884\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7377 - accuracy: 0.8879\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7318 - accuracy: 0.8914\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7239 - accuracy: 0.8905\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7163 - accuracy: 0.8940\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7034 - accuracy: 0.8954\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7070 - accuracy: 0.8926\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6925 - accuracy: 0.8980\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6727 - accuracy: 0.9046\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6674 - accuracy: 0.9048\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6628 - accuracy: 0.9088\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6586 - accuracy: 0.9081\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6524 - accuracy: 0.9118\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6500 - accuracy: 0.9100\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6485 - accuracy: 0.9125\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6541 - accuracy: 0.9039\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6568 - accuracy: 0.8987\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6427 - accuracy: 0.8978\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5947 - accuracy: 0.9137\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5947 - accuracy: 0.9121\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5842 - accuracy: 0.9177\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5795 - accuracy: 0.9170\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5752 - accuracy: 0.9224\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5719 - accuracy: 0.9210\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5705 - accuracy: 0.9226\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5735 - accuracy: 0.9212\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5899 - accuracy: 0.9165\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6150 - accuracy: 0.9043\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7247 - accuracy: 0.8816\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6763 - accuracy: 0.8849\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5380 - accuracy: 0.9233\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5945 - accuracy: 0.9062\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5273 - accuracy: 0.9231\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5151 - accuracy: 0.9268\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5110 - accuracy: 0.9273\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5082 - accuracy: 0.9283\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5059 - accuracy: 0.9297\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5040 - accuracy: 0.9306\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5024 - accuracy: 0.9313\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5012 - accuracy: 0.9318\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4988 - accuracy: 0.9313\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5760 - accuracy: 0.9097\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5091 - accuracy: 0.9283\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4837 - accuracy: 0.9313\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4761 - accuracy: 0.9318\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4735 - accuracy: 0.9332\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4720 - accuracy: 0.9329\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4680 - accuracy: 0.9336\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4655 - accuracy: 0.9339\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4644 - accuracy: 0.9339\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4638 - accuracy: 0.9343\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4643 - accuracy: 0.9341\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4658 - accuracy: 0.9341\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4687 - accuracy: 0.9329\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4717 - accuracy: 0.9325\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4749 - accuracy: 0.9304\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4761 - accuracy: 0.9301\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4715 - accuracy: 0.9299\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4620 - accuracy: 0.9320\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4563 - accuracy: 0.9355\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4547 - accuracy: 0.9353\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4537 - accuracy: 0.9353\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4530 - accuracy: 0.9353\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4525 - accuracy: 0.9355\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4520 - accuracy: 0.9355\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4519 - accuracy: 0.9355\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4520 - accuracy: 0.9353\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4530 - accuracy: 0.9351\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4543 - accuracy: 0.9353\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4571 - accuracy: 0.9348\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4673 - accuracy: 0.9320\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5409 - accuracy: 0.9238\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7152 - accuracy: 0.8936\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4812 - accuracy: 0.9315\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4519 - accuracy: 0.9348\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4478 - accuracy: 0.9355\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4466 - accuracy: 0.9358\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4459 - accuracy: 0.9355\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4453 - accuracy: 0.9358\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4449 - accuracy: 0.9362\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4445 - accuracy: 0.9365\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4441 - accuracy: 0.9362\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4439 - accuracy: 0.9362\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4436 - accuracy: 0.9369\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4433 - accuracy: 0.9372\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4431 - accuracy: 0.9369\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4429 - accuracy: 0.9372\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4428 - accuracy: 0.9369\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4427 - accuracy: 0.9372\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4426 - accuracy: 0.9372\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4426 - accuracy: 0.9369\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4428 - accuracy: 0.9379\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4428 - accuracy: 0.9369\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4426 - accuracy: 0.9376\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4424 - accuracy: 0.9372\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4423 - accuracy: 0.9379\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4421 - accuracy: 0.9372\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4418 - accuracy: 0.9374\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4415 - accuracy: 0.9374\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4413 - accuracy: 0.9379\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4412 - accuracy: 0.9374\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4411 - accuracy: 0.9376\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4410 - accuracy: 0.9379\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4411 - accuracy: 0.9376\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4413 - accuracy: 0.9381\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4441 - accuracy: 0.9365\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4576 - accuracy: 0.9320\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8196 - accuracy: 0.8488\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4804 - accuracy: 0.9261\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4156 - accuracy: 0.9353\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4095 - accuracy: 0.9381\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4081 - accuracy: 0.9383\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4072 - accuracy: 0.9393\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4067 - accuracy: 0.9395\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4063 - accuracy: 0.9397\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4059 - accuracy: 0.9400\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4056 - accuracy: 0.9400\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4053 - accuracy: 0.9400\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4051 - accuracy: 0.9400\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4049 - accuracy: 0.9400\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4047 - accuracy: 0.9400\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4046 - accuracy: 0.9400\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4044 - accuracy: 0.9400\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4043 - accuracy: 0.9400\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4042 - accuracy: 0.9402\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4041 - accuracy: 0.9404\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4020 - accuracy: 0.9402\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4087 - accuracy: 0.9348\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3966 - accuracy: 0.9360\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4246 - accuracy: 0.9339\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3986 - accuracy: 0.9367\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3861 - accuracy: 0.9419\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3842 - accuracy: 0.9419\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3835 - accuracy: 0.9419\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3830 - accuracy: 0.9421\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3827 - accuracy: 0.9421\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3824 - accuracy: 0.9423\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3822 - accuracy: 0.9421\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3820 - accuracy: 0.9421\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3818 - accuracy: 0.9421\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3817 - accuracy: 0.9421\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3816 - accuracy: 0.9421\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3814 - accuracy: 0.9421\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3814 - accuracy: 0.9421\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3813 - accuracy: 0.9421\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3813 - accuracy: 0.9421\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3812 - accuracy: 0.9421\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3812 - accuracy: 0.9421\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3812 - accuracy: 0.9423\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3811 - accuracy: 0.9423\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3811 - accuracy: 0.9423\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3810 - accuracy: 0.9421\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3810 - accuracy: 0.9423\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3809 - accuracy: 0.9421\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3809 - accuracy: 0.9423\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3809 - accuracy: 0.9426\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3809 - accuracy: 0.9423\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3811 - accuracy: 0.9421\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3822 - accuracy: 0.9421\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3905 - accuracy: 0.9393\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5054 - accuracy: 0.9299\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6124 - accuracy: 0.8992\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4066 - accuracy: 0.9402\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 2.7675 - accuracy: 0.6363\n",
      "[CV 2/2] END activation_function=relu, hidden1_neurons=128;, score=0.636 total time=   5.3s\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 4.7986 - accuracy: 0.5068\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.0970 - accuracy: 0.5014\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.6969 - accuracy: 0.5195\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.5441 - accuracy: 0.5589\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.2326 - accuracy: 0.5950\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.4500 - accuracy: 0.5863\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6296 - accuracy: 0.6534\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3332 - accuracy: 0.6646\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1822 - accuracy: 0.6818\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0755 - accuracy: 0.6982\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9888 - accuracy: 0.7115\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.1760 - accuracy: 0.6001\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9147 - accuracy: 0.7151\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6871 - accuracy: 0.7472\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6124 - accuracy: 0.7519\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5654 - accuracy: 0.7596\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5150 - accuracy: 0.7723\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4879 - accuracy: 0.7810\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4701 - accuracy: 0.7887\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4376 - accuracy: 0.7957\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4241 - accuracy: 0.7871\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3612 - accuracy: 0.8037\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3262 - accuracy: 0.8192\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3066 - accuracy: 0.8239\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2816 - accuracy: 0.8283\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2663 - accuracy: 0.8347\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2538 - accuracy: 0.8405\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2403 - accuracy: 0.8492\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2264 - accuracy: 0.8525\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2155 - accuracy: 0.8548\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2087 - accuracy: 0.8609\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2000 - accuracy: 0.8647\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1863 - accuracy: 0.8687\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1648 - accuracy: 0.8698\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1488 - accuracy: 0.8727\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1384 - accuracy: 0.8762\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1223 - accuracy: 0.8792\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1084 - accuracy: 0.8816\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1023 - accuracy: 0.8837\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0929 - accuracy: 0.8860\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0868 - accuracy: 0.8823\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0593 - accuracy: 0.8912\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0494 - accuracy: 0.8935\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0444 - accuracy: 0.8952\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0379 - accuracy: 0.8963\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0193 - accuracy: 0.8973\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0050 - accuracy: 0.8994\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0027 - accuracy: 0.8987\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9902 - accuracy: 0.8938\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9492 - accuracy: 0.9010\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9421 - accuracy: 0.9048\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9393 - accuracy: 0.9027\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9351 - accuracy: 0.9055\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9353 - accuracy: 0.8952\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8759 - accuracy: 0.9095\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8675 - accuracy: 0.9090\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8564 - accuracy: 0.9102\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8443 - accuracy: 0.9109\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8311 - accuracy: 0.9041\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8643 - accuracy: 0.8865\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7833 - accuracy: 0.8994\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1332 - accuracy: 0.7833\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7947 - accuracy: 0.8816\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6746 - accuracy: 0.9055\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7186 - accuracy: 0.9038\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6130 - accuracy: 0.9174\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5943 - accuracy: 0.9186\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5784 - accuracy: 0.9226\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5720 - accuracy: 0.9238\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5683 - accuracy: 0.9257\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5655 - accuracy: 0.9259\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5631 - accuracy: 0.9273\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5613 - accuracy: 0.9282\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5516 - accuracy: 0.9301\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5466 - accuracy: 0.9322\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5446 - accuracy: 0.9332\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5431 - accuracy: 0.9341\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5396 - accuracy: 0.9339\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5371 - accuracy: 0.9348\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5360 - accuracy: 0.9348\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5342 - accuracy: 0.9360\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5387 - accuracy: 0.9339\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5469 - accuracy: 0.9299\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5420 - accuracy: 0.9301\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5595 - accuracy: 0.9189\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6018 - accuracy: 0.9144\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5835 - accuracy: 0.9095\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5713 - accuracy: 0.9196\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4903 - accuracy: 0.9343\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4633 - accuracy: 0.9411\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4577 - accuracy: 0.9404\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4555 - accuracy: 0.9418\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4539 - accuracy: 0.9423\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4526 - accuracy: 0.9428\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4515 - accuracy: 0.9430\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4506 - accuracy: 0.9430\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4499 - accuracy: 0.9430\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4497 - accuracy: 0.9439\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4500 - accuracy: 0.9428\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4511 - accuracy: 0.9428\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4519 - accuracy: 0.9418\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4524 - accuracy: 0.9425\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4475 - accuracy: 0.9432\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4470 - accuracy: 0.9421\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4447 - accuracy: 0.9435\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4435 - accuracy: 0.9442\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4427 - accuracy: 0.9447\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4421 - accuracy: 0.9444\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4416 - accuracy: 0.9447\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4415 - accuracy: 0.9444\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4415 - accuracy: 0.9447\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4375 - accuracy: 0.9435\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4378 - accuracy: 0.9430\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4557 - accuracy: 0.9409\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8014 - accuracy: 0.8398\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2789 - accuracy: 0.7012\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7606 - accuracy: 0.8595\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4405 - accuracy: 0.9383\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4285 - accuracy: 0.9407\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4249 - accuracy: 0.9428\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4206 - accuracy: 0.9442\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4105 - accuracy: 0.9449\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5481 - accuracy: 0.9174\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4019 - accuracy: 0.9421\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4039 - accuracy: 0.9402\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4559 - accuracy: 0.9329\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4047 - accuracy: 0.9409\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3864 - accuracy: 0.9428\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3832 - accuracy: 0.9437\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3816 - accuracy: 0.9444\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3803 - accuracy: 0.9447\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3793 - accuracy: 0.9475\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3784 - accuracy: 0.9484\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3776 - accuracy: 0.9486\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3745 - accuracy: 0.9484\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3731 - accuracy: 0.9486\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3724 - accuracy: 0.9482\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3720 - accuracy: 0.9484\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3715 - accuracy: 0.9486\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3711 - accuracy: 0.9486\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3709 - accuracy: 0.9489\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3706 - accuracy: 0.9486\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3703 - accuracy: 0.9489\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3701 - accuracy: 0.9491\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3699 - accuracy: 0.9493\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3697 - accuracy: 0.9493\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3695 - accuracy: 0.9493\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3676 - accuracy: 0.9493\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3902 - accuracy: 0.9416\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3650 - accuracy: 0.9461\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3518 - accuracy: 0.9484\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3486 - accuracy: 0.9484\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3477 - accuracy: 0.9491\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3472 - accuracy: 0.9493\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3468 - accuracy: 0.9498\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3466 - accuracy: 0.9500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3463 - accuracy: 0.9500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3461 - accuracy: 0.9503\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3459 - accuracy: 0.9505\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3458 - accuracy: 0.9505\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3457 - accuracy: 0.9505\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3455 - accuracy: 0.9505\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3455 - accuracy: 0.9503\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3453 - accuracy: 0.9508\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3455 - accuracy: 0.9503\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3455 - accuracy: 0.9500\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3462 - accuracy: 0.9496\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3478 - accuracy: 0.9491\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3549 - accuracy: 0.9484\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4511 - accuracy: 0.9376\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6519 - accuracy: 0.8595\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6118 - accuracy: 0.8788\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4630 - accuracy: 0.9348\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3265 - accuracy: 0.9458\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3220 - accuracy: 0.9418\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2943 - accuracy: 0.9524\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2903 - accuracy: 0.9531\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2890 - accuracy: 0.9545\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2881 - accuracy: 0.9550\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2857 - accuracy: 0.9550\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3479 - accuracy: 0.9435\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2861 - accuracy: 0.9522\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2794 - accuracy: 0.9540\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2779 - accuracy: 0.9545\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2771 - accuracy: 0.9545\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2766 - accuracy: 0.9550\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2762 - accuracy: 0.9557\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2758 - accuracy: 0.9557\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2756 - accuracy: 0.9557\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2754 - accuracy: 0.9557\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2752 - accuracy: 0.9559\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2750 - accuracy: 0.9559\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2749 - accuracy: 0.9561\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2747 - accuracy: 0.9561\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2746 - accuracy: 0.9561\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2745 - accuracy: 0.9561\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2743 - accuracy: 0.9561\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2743 - accuracy: 0.9561\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2742 - accuracy: 0.9561\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2741 - accuracy: 0.9561\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 2.8473 - accuracy: 0.6206\n",
      "[CV 1/2] END activation_function=relu, hidden1_neurons=256;, score=0.621 total time=   6.6s\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 7.3728 - accuracy: 0.4928\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.3720 - accuracy: 0.4975\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7873 - accuracy: 0.5135\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.3197 - accuracy: 0.5726\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.8375 - accuracy: 0.5970\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.4500 - accuracy: 0.6267\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2571 - accuracy: 0.6302\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.6744 - accuracy: 0.6124\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9624 - accuracy: 0.6877\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7701 - accuracy: 0.7247\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6576 - accuracy: 0.7332\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.6102 - accuracy: 0.7421\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5782 - accuracy: 0.7538\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5495 - accuracy: 0.7653\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5234 - accuracy: 0.7754\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5361 - accuracy: 0.7268\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3719 - accuracy: 0.7958\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2966 - accuracy: 0.8000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2724 - accuracy: 0.8035\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2495 - accuracy: 0.8185\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2322 - accuracy: 0.8256\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2207 - accuracy: 0.8312\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2064 - accuracy: 0.8387\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1932 - accuracy: 0.8436\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1783 - accuracy: 0.8492\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1668 - accuracy: 0.8530\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1586 - accuracy: 0.8610\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1469 - accuracy: 0.8617\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1333 - accuracy: 0.8635\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1161 - accuracy: 0.8687\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1000 - accuracy: 0.8703\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0957 - accuracy: 0.8746\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0793 - accuracy: 0.8729\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0596 - accuracy: 0.8776\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0387 - accuracy: 0.8816\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0292 - accuracy: 0.8844\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0169 - accuracy: 0.8837\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0090 - accuracy: 0.8828\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9849 - accuracy: 0.8877\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9602 - accuracy: 0.8858\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9373 - accuracy: 0.8943\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9350 - accuracy: 0.8917\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9311 - accuracy: 0.8928\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9204 - accuracy: 0.8938\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9016 - accuracy: 0.8938\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9566 - accuracy: 0.8490\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8193 - accuracy: 0.8938\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7779 - accuracy: 0.9025\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7659 - accuracy: 0.9029\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7598 - accuracy: 0.9088\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7537 - accuracy: 0.9076\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7494 - accuracy: 0.9102\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7496 - accuracy: 0.9111\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7520 - accuracy: 0.9095\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7472 - accuracy: 0.8994\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7006 - accuracy: 0.9135\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6928 - accuracy: 0.9142\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7058 - accuracy: 0.9102\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7118 - accuracy: 0.9067\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7289 - accuracy: 0.8910\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8551 - accuracy: 0.8647\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8241 - accuracy: 0.8556\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0039 - accuracy: 0.8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6048 - accuracy: 0.9097\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7082 - accuracy: 0.9013\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5669 - accuracy: 0.9154\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5260 - accuracy: 0.9215\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5061 - accuracy: 0.9250\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5043 - accuracy: 0.9268\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4978 - accuracy: 0.9285\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4949 - accuracy: 0.9294\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4927 - accuracy: 0.9306\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4908 - accuracy: 0.9313\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4892 - accuracy: 0.9318\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4880 - accuracy: 0.9318\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4869 - accuracy: 0.9320\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4867 - accuracy: 0.9325\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4858 - accuracy: 0.9322\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4852 - accuracy: 0.9320\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4843 - accuracy: 0.9322\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4831 - accuracy: 0.9325\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4817 - accuracy: 0.9329\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4802 - accuracy: 0.9339\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4793 - accuracy: 0.9339\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4786 - accuracy: 0.9341\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4781 - accuracy: 0.9348\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4777 - accuracy: 0.9351\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4783 - accuracy: 0.9353\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4807 - accuracy: 0.9339\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4965 - accuracy: 0.9294\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6449 - accuracy: 0.9130\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9119 - accuracy: 0.7576\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5415 - accuracy: 0.9240\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4917 - accuracy: 0.9306\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4828 - accuracy: 0.9320\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4771 - accuracy: 0.9339\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4748 - accuracy: 0.9341\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4735 - accuracy: 0.9346\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4725 - accuracy: 0.9358\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4719 - accuracy: 0.9355\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4713 - accuracy: 0.9355\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4709 - accuracy: 0.9355\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4705 - accuracy: 0.9355\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4651 - accuracy: 0.9360\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4631 - accuracy: 0.9358\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4626 - accuracy: 0.9358\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4623 - accuracy: 0.9358\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4620 - accuracy: 0.9360\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4618 - accuracy: 0.9367\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4617 - accuracy: 0.9365\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4617 - accuracy: 0.9367\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4600 - accuracy: 0.9362\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4590 - accuracy: 0.9353\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4601 - accuracy: 0.9329\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5023 - accuracy: 0.9240\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6566 - accuracy: 0.9191\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0404 - accuracy: 0.7695\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6319 - accuracy: 0.9074\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4750 - accuracy: 0.9315\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4687 - accuracy: 0.9343\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4667 - accuracy: 0.9351\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4653 - accuracy: 0.9355\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4644 - accuracy: 0.9365\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4637 - accuracy: 0.9365\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4631 - accuracy: 0.9369\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4602 - accuracy: 0.9374\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4468 - accuracy: 0.9374\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4384 - accuracy: 0.9365\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4351 - accuracy: 0.9386\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4344 - accuracy: 0.9388\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4341 - accuracy: 0.9393\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4338 - accuracy: 0.9393\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4336 - accuracy: 0.9395\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4334 - accuracy: 0.9393\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4332 - accuracy: 0.9395\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4330 - accuracy: 0.9393\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4329 - accuracy: 0.9395\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4327 - accuracy: 0.9393\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4326 - accuracy: 0.9395\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4325 - accuracy: 0.9395\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4324 - accuracy: 0.9395\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4323 - accuracy: 0.9395\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4322 - accuracy: 0.9395\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4321 - accuracy: 0.9397\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4320 - accuracy: 0.9395\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4320 - accuracy: 0.9397\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4320 - accuracy: 0.9397\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4320 - accuracy: 0.9395\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4321 - accuracy: 0.9397\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4296 - accuracy: 0.9395\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4281 - accuracy: 0.9397\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4279 - accuracy: 0.9397\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4279 - accuracy: 0.9402\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4279 - accuracy: 0.9397\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4279 - accuracy: 0.9400\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4282 - accuracy: 0.9397\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4276 - accuracy: 0.9393\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4394 - accuracy: 0.9334\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4738 - accuracy: 0.9306\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8175 - accuracy: 0.8363\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9909 - accuracy: 0.7869\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6001 - accuracy: 0.9140\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4248 - accuracy: 0.9325\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4587 - accuracy: 0.9308\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4163 - accuracy: 0.9329\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3942 - accuracy: 0.9383\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3870 - accuracy: 0.9397\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3846 - accuracy: 0.9407\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3835 - accuracy: 0.9411\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3827 - accuracy: 0.9414\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3821 - accuracy: 0.9414\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3817 - accuracy: 0.9414\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3813 - accuracy: 0.9416\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3810 - accuracy: 0.9416\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3807 - accuracy: 0.9416\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3805 - accuracy: 0.9416\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3803 - accuracy: 0.9430\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3801 - accuracy: 0.9430\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3799 - accuracy: 0.9433\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3797 - accuracy: 0.9435\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3796 - accuracy: 0.9435\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3795 - accuracy: 0.9435\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3794 - accuracy: 0.9435\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3793 - accuracy: 0.9435\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3792 - accuracy: 0.9435\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3791 - accuracy: 0.9437\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3790 - accuracy: 0.9437\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3789 - accuracy: 0.9440\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3789 - accuracy: 0.9437\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3788 - accuracy: 0.9437\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3765 - accuracy: 0.9437\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3936 - accuracy: 0.9374\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4610 - accuracy: 0.9320\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5178 - accuracy: 0.9271\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5081 - accuracy: 0.9217\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4295 - accuracy: 0.9390\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3996 - accuracy: 0.9390\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3449 - accuracy: 0.9447\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3392 - accuracy: 0.9437\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3327 - accuracy: 0.9458\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 2.8057 - accuracy: 0.6313\n",
      "[CV 2/2] END activation_function=relu, hidden1_neurons=256;, score=0.631 total time=   6.5s\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 3.9299 - accuracy: 0.4988\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8891 - accuracy: 0.5301\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.1398 - accuracy: 0.5353\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.0295 - accuracy: 0.5832\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.5616 - accuracy: 0.6177\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1582 - accuracy: 0.6362\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9154 - accuracy: 0.6413\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8061 - accuracy: 0.6504\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6354 - accuracy: 0.6592\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5077 - accuracy: 0.6715\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4145 - accuracy: 0.6794\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3616 - accuracy: 0.6884\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3271 - accuracy: 0.6959\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3051 - accuracy: 0.7035\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2870 - accuracy: 0.7124\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2554 - accuracy: 0.7207\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2286 - accuracy: 0.7268\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1952 - accuracy: 0.7371\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1581 - accuracy: 0.7424\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1317 - accuracy: 0.7521\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1188 - accuracy: 0.7595\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1074 - accuracy: 0.7659\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0933 - accuracy: 0.7717\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0839 - accuracy: 0.7796\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0761 - accuracy: 0.7839\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0662 - accuracy: 0.7907\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0548 - accuracy: 0.7968\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0345 - accuracy: 0.8019\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0177 - accuracy: 0.8072\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0086 - accuracy: 0.8133\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9995 - accuracy: 0.8178\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9625 - accuracy: 0.8051\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9243 - accuracy: 0.8233\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9032 - accuracy: 0.8316\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8899 - accuracy: 0.8369\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8811 - accuracy: 0.8403\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8678 - accuracy: 0.8443\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8555 - accuracy: 0.8469\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8288 - accuracy: 0.8465\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8088 - accuracy: 0.8462\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7876 - accuracy: 0.8566\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7868 - accuracy: 0.8499\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7655 - accuracy: 0.8564\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7702 - accuracy: 0.8421\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7623 - accuracy: 0.8253\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9737 - accuracy: 0.7575\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5593 - accuracy: 0.6771\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7878 - accuracy: 0.8159\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6810 - accuracy: 0.8733\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6521 - accuracy: 0.8784\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6221 - accuracy: 0.8816\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6078 - accuracy: 0.8851\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6024 - accuracy: 0.8871\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5978 - accuracy: 0.8897\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5937 - accuracy: 0.8911\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5898 - accuracy: 0.8926\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5862 - accuracy: 0.8942\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5807 - accuracy: 0.8952\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5761 - accuracy: 0.8973\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5722 - accuracy: 0.8992\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5691 - accuracy: 0.8996\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5648 - accuracy: 0.9017\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5576 - accuracy: 0.9028\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5541 - accuracy: 0.9049\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5509 - accuracy: 0.9060\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5487 - accuracy: 0.9068\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5425 - accuracy: 0.9085\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5420 - accuracy: 0.9101\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5461 - accuracy: 0.9067\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5488 - accuracy: 0.9009\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5252 - accuracy: 0.9107\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5261 - accuracy: 0.9116\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5279 - accuracy: 0.9068\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5256 - accuracy: 0.9054\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5262 - accuracy: 0.9017\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5340 - accuracy: 0.8973\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5312 - accuracy: 0.8914\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5415 - accuracy: 0.8883\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5215 - accuracy: 0.8893\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4880 - accuracy: 0.9088\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4658 - accuracy: 0.9163\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4495 - accuracy: 0.9229\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4420 - accuracy: 0.9258\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4428 - accuracy: 0.9240\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4415 - accuracy: 0.9239\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4445 - accuracy: 0.9239\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4536 - accuracy: 0.9185\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4736 - accuracy: 0.9132\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5003 - accuracy: 0.8947\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8399 - accuracy: 0.8197\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4521 - accuracy: 0.9144\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4269 - accuracy: 0.9252\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4220 - accuracy: 0.9259\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4187 - accuracy: 0.9265\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4160 - accuracy: 0.9273\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4138 - accuracy: 0.9275\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4120 - accuracy: 0.9287\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4110 - accuracy: 0.9292\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4105 - accuracy: 0.9292\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4108 - accuracy: 0.9299\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4113 - accuracy: 0.9298\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4127 - accuracy: 0.9300\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4136 - accuracy: 0.9285\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4165 - accuracy: 0.9287\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4168 - accuracy: 0.9271\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4194 - accuracy: 0.9279\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4220 - accuracy: 0.9246\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4224 - accuracy: 0.9265\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4193 - accuracy: 0.9251\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4118 - accuracy: 0.9288\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4029 - accuracy: 0.9308\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3971 - accuracy: 0.9332\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3945 - accuracy: 0.9339\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3925 - accuracy: 0.9346\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3913 - accuracy: 0.9345\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3912 - accuracy: 0.9347\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3946 - accuracy: 0.9340\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4050 - accuracy: 0.9314\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4450 - accuracy: 0.9200\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6037 - accuracy: 0.8907\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4980 - accuracy: 0.9042\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4337 - accuracy: 0.9244\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4686 - accuracy: 0.9110\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3758 - accuracy: 0.9341\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3633 - accuracy: 0.9359\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3536 - accuracy: 0.9379\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3503 - accuracy: 0.9389\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3482 - accuracy: 0.9386\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3467 - accuracy: 0.9389\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3457 - accuracy: 0.9394\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3451 - accuracy: 0.9390\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3448 - accuracy: 0.9388\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3454 - accuracy: 0.9387\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3464 - accuracy: 0.9386\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3485 - accuracy: 0.9377\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3501 - accuracy: 0.9382\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3614 - accuracy: 0.9343\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3789 - accuracy: 0.9306\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4608 - accuracy: 0.9137\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4800 - accuracy: 0.9091\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4392 - accuracy: 0.9165\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3413 - accuracy: 0.9372\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3276 - accuracy: 0.9408\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3228 - accuracy: 0.9411\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3214 - accuracy: 0.9414\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3202 - accuracy: 0.9414\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3194 - accuracy: 0.9416\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3188 - accuracy: 0.9415\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3171 - accuracy: 0.9417\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3164 - accuracy: 0.9421\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3164 - accuracy: 0.9414\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3170 - accuracy: 0.9420\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3187 - accuracy: 0.9414\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3217 - accuracy: 0.9403\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3305 - accuracy: 0.9383\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3518 - accuracy: 0.9329\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4539 - accuracy: 0.9190\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5879 - accuracy: 0.8960\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4840 - accuracy: 0.9051\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3623 - accuracy: 0.9370\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3391 - accuracy: 0.9399\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3266 - accuracy: 0.9403\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3221 - accuracy: 0.9406\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3205 - accuracy: 0.9408\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3195 - accuracy: 0.9411\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3187 - accuracy: 0.9414\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3181 - accuracy: 0.9417\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3175 - accuracy: 0.9418\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3159 - accuracy: 0.9418\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3151 - accuracy: 0.9423\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3147 - accuracy: 0.9423\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3142 - accuracy: 0.9427\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3138 - accuracy: 0.9425\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3135 - accuracy: 0.9428\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3132 - accuracy: 0.9434\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3118 - accuracy: 0.9435\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3111 - accuracy: 0.9437\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3107 - accuracy: 0.9440\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3104 - accuracy: 0.9440\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3101 - accuracy: 0.9442\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3102 - accuracy: 0.9438\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3109 - accuracy: 0.9438\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3138 - accuracy: 0.9433\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3137 - accuracy: 0.9413\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3185 - accuracy: 0.9408\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3298 - accuracy: 0.9363\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3986 - accuracy: 0.9275\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4401 - accuracy: 0.9209\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3891 - accuracy: 0.9278\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3025 - accuracy: 0.9428\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2969 - accuracy: 0.9443\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2954 - accuracy: 0.9445\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2945 - accuracy: 0.9445\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2939 - accuracy: 0.9448\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2934 - accuracy: 0.9451\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2930 - accuracy: 0.9451\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2927 - accuracy: 0.9452\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2924 - accuracy: 0.9451\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2921 - accuracy: 0.9455\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2919 - accuracy: 0.9454\n",
      "The optimal activation function is relu\n",
      "The optimal number of neurons per hidden layer is 128\n"
     ]
    }
   ],
   "source": [
    "## Perform hyperparameter tuning using the guidelines shared above\n",
    "  \n",
    "# Define the 'build_fn' parameter for KerasClassifier using your create_nn function\n",
    "base_grid_model = KerasClassifier(build_fn=create_nn)\n",
    "\n",
    "# Define the range of parameters\n",
    "parameters_grid = {'activation_function': ['sigmoid', 'relu'], 'hidden1_neurons': [128, 256]}\n",
    "\n",
    "# Perform grid search using GridSearchCV\n",
    "grid = GridSearchCV(estimator=base_grid_model, param_grid=parameters_grid, cv=2, verbose=4)\n",
    "\n",
    "# Instead of directly using nn, pass the create_nn function to KerasClassifier\n",
    "grid_model = grid.fit(Tfidf_train, y_train, batch_size=Tfidf_train.shape[0], epochs=200)\n",
    "\n",
    "# Print the optimal values of parameters\n",
    "best_activation = grid_model.best_params_['activation_function']\n",
    "best_n_neurons = grid_model.best_params_['hidden1_neurons']\n",
    "\n",
    "print('The optimal activation function is', best_activation)\n",
    "print('The optimal number of neurons per hidden layer is', best_n_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3G3ie3hRRGIv"
   },
   "source": [
    "### Building the optimal model\n",
    "\n",
    "Once you have evaluated the performance for all the combination of hyperparameters, it's time to build the final model using the optimal values.\n",
    "\n",
    "### Guidelines\n",
    "\n",
    "- You can evaluate how the training and validation accuracies are changing for the different combination of hyperparameters in the previous step.This should give you an idea of the most optimal performance values that you can expect.\n",
    "\n",
    "- Identify the hyperparameters for the best model, and use it to retrain the model.\n",
    "\n",
    "- *Note that the validation accuracy may not be at par with the conventional models*. You should expect this and need not worry in case you get low values for validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "6x_jI7bAE3Do"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tfidf_max_features (InputLa  [(None, 500)]            0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               64128     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,449\n",
      "Trainable params: 72,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 4.2410 - accuracy: 0.5037 - val_loss: 4.9347 - val_accuracy: 0.5275\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.9753 - accuracy: 0.5210 - val_loss: 3.2212 - val_accuracy: 0.5469\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.0521 - accuracy: 0.5669 - val_loss: 2.9582 - val_accuracy: 0.5651\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.6096 - accuracy: 0.5964 - val_loss: 2.6983 - val_accuracy: 0.5744\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2933 - accuracy: 0.6299 - val_loss: 3.0187 - val_accuracy: 0.5739\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.4983 - accuracy: 0.6101 - val_loss: 2.6359 - val_accuracy: 0.5873\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.0657 - accuracy: 0.6441 - val_loss: 2.4973 - val_accuracy: 0.5920\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.9484 - accuracy: 0.6531 - val_loss: 2.2968 - val_accuracy: 0.5967\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.7266 - accuracy: 0.6849 - val_loss: 2.3061 - val_accuracy: 0.6032\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6759 - accuracy: 0.6767 - val_loss: 2.3378 - val_accuracy: 0.5955\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5769 - accuracy: 0.6906 - val_loss: 2.1188 - val_accuracy: 0.5961\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3870 - accuracy: 0.7042 - val_loss: 2.0484 - val_accuracy: 0.6032\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3477 - accuracy: 0.7083 - val_loss: 2.0469 - val_accuracy: 0.6084\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3243 - accuracy: 0.7163 - val_loss: 1.9896 - val_accuracy: 0.6061\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2971 - accuracy: 0.7201 - val_loss: 1.9434 - val_accuracy: 0.6079\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.2799 - accuracy: 0.7265 - val_loss: 1.9236 - val_accuracy: 0.6143\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2661 - accuracy: 0.7321 - val_loss: 1.9301 - val_accuracy: 0.6137\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2514 - accuracy: 0.7390 - val_loss: 1.9514 - val_accuracy: 0.6137\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2327 - accuracy: 0.7445 - val_loss: 2.0561 - val_accuracy: 0.6131\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1945 - accuracy: 0.7495 - val_loss: 1.9766 - val_accuracy: 0.6149\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1593 - accuracy: 0.7551 - val_loss: 1.8899 - val_accuracy: 0.6120\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1372 - accuracy: 0.7659 - val_loss: 1.8851 - val_accuracy: 0.6114\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1250 - accuracy: 0.7722 - val_loss: 2.0221 - val_accuracy: 0.6213\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1348 - accuracy: 0.7538 - val_loss: 1.9072 - val_accuracy: 0.6249\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0507 - accuracy: 0.7695 - val_loss: 1.9134 - val_accuracy: 0.6137\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0052 - accuracy: 0.7841 - val_loss: 1.8384 - val_accuracy: 0.6196\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9842 - accuracy: 0.7894 - val_loss: 1.8667 - val_accuracy: 0.6208\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9743 - accuracy: 0.7929 - val_loss: 1.8629 - val_accuracy: 0.6196\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9663 - accuracy: 0.8004 - val_loss: 1.8692 - val_accuracy: 0.6213\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9589 - accuracy: 0.8060 - val_loss: 1.8627 - val_accuracy: 0.6243\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9519 - accuracy: 0.8099 - val_loss: 1.8637 - val_accuracy: 0.6231\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9436 - accuracy: 0.8165 - val_loss: 1.8671 - val_accuracy: 0.6243\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9332 - accuracy: 0.8210 - val_loss: 1.8990 - val_accuracy: 0.6243\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9244 - accuracy: 0.8257 - val_loss: 1.8719 - val_accuracy: 0.6325\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9167 - accuracy: 0.8268 - val_loss: 1.8860 - val_accuracy: 0.6254\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9056 - accuracy: 0.8342 - val_loss: 1.8790 - val_accuracy: 0.6278\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8962 - accuracy: 0.8392 - val_loss: 1.9041 - val_accuracy: 0.6307\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8896 - accuracy: 0.8454 - val_loss: 1.9117 - val_accuracy: 0.6325\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8836 - accuracy: 0.8499 - val_loss: 1.9097 - val_accuracy: 0.6319\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8766 - accuracy: 0.8527 - val_loss: 1.9337 - val_accuracy: 0.6319\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8706 - accuracy: 0.8556 - val_loss: 1.9530 - val_accuracy: 0.6331\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8590 - accuracy: 0.8596 - val_loss: 1.9141 - val_accuracy: 0.6331\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8444 - accuracy: 0.8606 - val_loss: 1.9498 - val_accuracy: 0.6336\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8318 - accuracy: 0.8638 - val_loss: 1.9748 - val_accuracy: 0.6407\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8272 - accuracy: 0.8597 - val_loss: 2.0623 - val_accuracy: 0.6360\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8074 - accuracy: 0.8523 - val_loss: 2.0257 - val_accuracy: 0.6377\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7950 - accuracy: 0.8572 - val_loss: 2.0931 - val_accuracy: 0.6401\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7658 - accuracy: 0.8504 - val_loss: 1.9424 - val_accuracy: 0.6389\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7154 - accuracy: 0.8729 - val_loss: 1.8809 - val_accuracy: 0.6419\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7030 - accuracy: 0.8811 - val_loss: 1.9663 - val_accuracy: 0.6460\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6934 - accuracy: 0.8848 - val_loss: 1.9356 - val_accuracy: 0.6442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6887 - accuracy: 0.8857 - val_loss: 1.9795 - val_accuracy: 0.6401\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6912 - accuracy: 0.8855 - val_loss: 2.1200 - val_accuracy: 0.6448\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6999 - accuracy: 0.8723 - val_loss: 2.0682 - val_accuracy: 0.6407\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6799 - accuracy: 0.8788 - val_loss: 2.0170 - val_accuracy: 0.6512\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6638 - accuracy: 0.8823 - val_loss: 2.1180 - val_accuracy: 0.6372\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6681 - accuracy: 0.8767 - val_loss: 2.0580 - val_accuracy: 0.6489\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6454 - accuracy: 0.8814 - val_loss: 2.1293 - val_accuracy: 0.6354\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6425 - accuracy: 0.8848 - val_loss: 2.1017 - val_accuracy: 0.6430\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6389 - accuracy: 0.8778 - val_loss: 2.1739 - val_accuracy: 0.6407\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6326 - accuracy: 0.8804 - val_loss: 2.1017 - val_accuracy: 0.6471\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6147 - accuracy: 0.8880 - val_loss: 2.1055 - val_accuracy: 0.6395\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5968 - accuracy: 0.8996 - val_loss: 2.0677 - val_accuracy: 0.6547\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5855 - accuracy: 0.9050 - val_loss: 2.0568 - val_accuracy: 0.6442\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5801 - accuracy: 0.9081 - val_loss: 2.0656 - val_accuracy: 0.6518\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5710 - accuracy: 0.9121 - val_loss: 2.0577 - val_accuracy: 0.6460\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5678 - accuracy: 0.9140 - val_loss: 2.0909 - val_accuracy: 0.6536\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5692 - accuracy: 0.9129 - val_loss: 2.1945 - val_accuracy: 0.6377\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5788 - accuracy: 0.9077 - val_loss: 2.1991 - val_accuracy: 0.6383\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5940 - accuracy: 0.8983 - val_loss: 2.0550 - val_accuracy: 0.6501\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5516 - accuracy: 0.9165 - val_loss: 2.0923 - val_accuracy: 0.6536\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5451 - accuracy: 0.9184 - val_loss: 2.0723 - val_accuracy: 0.6477\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5410 - accuracy: 0.9207 - val_loss: 2.0840 - val_accuracy: 0.6506\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5427 - accuracy: 0.9181 - val_loss: 2.2305 - val_accuracy: 0.6366\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5526 - accuracy: 0.9156 - val_loss: 2.2813 - val_accuracy: 0.6348\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5768 - accuracy: 0.9015 - val_loss: 2.4357 - val_accuracy: 0.6354\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5870 - accuracy: 0.8945 - val_loss: 2.5525 - val_accuracy: 0.6231\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6648 - accuracy: 0.8688 - val_loss: 2.4177 - val_accuracy: 0.6366\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5936 - accuracy: 0.8888 - val_loss: 2.2203 - val_accuracy: 0.6518\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5146 - accuracy: 0.9182 - val_loss: 2.0689 - val_accuracy: 0.6407\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4874 - accuracy: 0.9250 - val_loss: 2.1463 - val_accuracy: 0.6518\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4812 - accuracy: 0.9282 - val_loss: 2.0638 - val_accuracy: 0.6442\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4764 - accuracy: 0.9285 - val_loss: 2.1127 - val_accuracy: 0.6489\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4733 - accuracy: 0.9294 - val_loss: 2.0821 - val_accuracy: 0.6424\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4711 - accuracy: 0.9289 - val_loss: 2.1399 - val_accuracy: 0.6506\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4706 - accuracy: 0.9296 - val_loss: 2.1392 - val_accuracy: 0.6383\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4725 - accuracy: 0.9291 - val_loss: 2.1355 - val_accuracy: 0.6465\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4762 - accuracy: 0.9277 - val_loss: 2.2712 - val_accuracy: 0.6489\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4837 - accuracy: 0.9251 - val_loss: 2.2131 - val_accuracy: 0.6419\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4891 - accuracy: 0.9231 - val_loss: 2.3502 - val_accuracy: 0.6419\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4969 - accuracy: 0.9198 - val_loss: 2.3114 - val_accuracy: 0.6401\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4962 - accuracy: 0.9182 - val_loss: 2.3301 - val_accuracy: 0.6436\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4912 - accuracy: 0.9204 - val_loss: 2.2393 - val_accuracy: 0.6489\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4748 - accuracy: 0.9257 - val_loss: 2.2048 - val_accuracy: 0.6442\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4629 - accuracy: 0.9314 - val_loss: 2.1659 - val_accuracy: 0.6454\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4577 - accuracy: 0.9332 - val_loss: 2.1134 - val_accuracy: 0.6413\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4547 - accuracy: 0.9351 - val_loss: 2.1385 - val_accuracy: 0.6413\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4530 - accuracy: 0.9351 - val_loss: 2.1477 - val_accuracy: 0.6401\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4519 - accuracy: 0.9352 - val_loss: 2.1769 - val_accuracy: 0.6424\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4524 - accuracy: 0.9348 - val_loss: 2.2467 - val_accuracy: 0.6489\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4551 - accuracy: 0.9340 - val_loss: 2.2592 - val_accuracy: 0.6413\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4620 - accuracy: 0.9314 - val_loss: 2.4345 - val_accuracy: 0.6424\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4811 - accuracy: 0.9266 - val_loss: 2.6118 - val_accuracy: 0.6272\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5427 - accuracy: 0.9151 - val_loss: 2.7771 - val_accuracy: 0.6372\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5730 - accuracy: 0.9052 - val_loss: 2.3155 - val_accuracy: 0.6419\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4556 - accuracy: 0.9292 - val_loss: 2.2537 - val_accuracy: 0.6495\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4296 - accuracy: 0.9352 - val_loss: 2.2032 - val_accuracy: 0.6477\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4206 - accuracy: 0.9355 - val_loss: 2.2307 - val_accuracy: 0.6448\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4178 - accuracy: 0.9367 - val_loss: 2.2332 - val_accuracy: 0.6419\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4160 - accuracy: 0.9371 - val_loss: 2.2397 - val_accuracy: 0.6430\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4148 - accuracy: 0.9373 - val_loss: 2.2440 - val_accuracy: 0.6389\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4141 - accuracy: 0.9373 - val_loss: 2.2501 - val_accuracy: 0.6489\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4142 - accuracy: 0.9377 - val_loss: 2.2577 - val_accuracy: 0.6419\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4148 - accuracy: 0.9373 - val_loss: 2.2641 - val_accuracy: 0.6506\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4167 - accuracy: 0.9370 - val_loss: 2.3084 - val_accuracy: 0.6372\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4205 - accuracy: 0.9357 - val_loss: 2.4138 - val_accuracy: 0.6530\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4300 - accuracy: 0.9333 - val_loss: 2.4469 - val_accuracy: 0.6383\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4425 - accuracy: 0.9282 - val_loss: 2.6848 - val_accuracy: 0.6407\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4703 - accuracy: 0.9228 - val_loss: 2.7667 - val_accuracy: 0.6254\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5306 - accuracy: 0.9147 - val_loss: 2.6035 - val_accuracy: 0.6501\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4606 - accuracy: 0.9216 - val_loss: 2.3776 - val_accuracy: 0.6465\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4115 - accuracy: 0.9357 - val_loss: 2.3269 - val_accuracy: 0.6424\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4036 - accuracy: 0.9386 - val_loss: 2.3239 - val_accuracy: 0.6454\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4017 - accuracy: 0.9386 - val_loss: 2.3213 - val_accuracy: 0.6460\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4004 - accuracy: 0.9387 - val_loss: 2.3308 - val_accuracy: 0.6454\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3995 - accuracy: 0.9395 - val_loss: 2.3407 - val_accuracy: 0.6471\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3988 - accuracy: 0.9395 - val_loss: 2.3473 - val_accuracy: 0.6477\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3983 - accuracy: 0.9395 - val_loss: 2.3452 - val_accuracy: 0.6477\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3978 - accuracy: 0.9398 - val_loss: 2.3629 - val_accuracy: 0.6460\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3975 - accuracy: 0.9395 - val_loss: 2.3270 - val_accuracy: 0.6465\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3977 - accuracy: 0.9393 - val_loss: 2.3715 - val_accuracy: 0.6424\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3982 - accuracy: 0.9392 - val_loss: 2.3458 - val_accuracy: 0.6489\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3987 - accuracy: 0.9389 - val_loss: 2.3584 - val_accuracy: 0.6401\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3992 - accuracy: 0.9387 - val_loss: 2.3665 - val_accuracy: 0.6483\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3967 - accuracy: 0.9383 - val_loss: 2.3601 - val_accuracy: 0.6442\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3926 - accuracy: 0.9393 - val_loss: 2.3767 - val_accuracy: 0.6506\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3916 - accuracy: 0.9395 - val_loss: 2.3850 - val_accuracy: 0.6465\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3910 - accuracy: 0.9395 - val_loss: 2.3874 - val_accuracy: 0.6512\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3907 - accuracy: 0.9398 - val_loss: 2.3794 - val_accuracy: 0.6436\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3906 - accuracy: 0.9395 - val_loss: 2.3954 - val_accuracy: 0.6512\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3913 - accuracy: 0.9392 - val_loss: 2.3823 - val_accuracy: 0.6377\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3937 - accuracy: 0.9387 - val_loss: 2.4651 - val_accuracy: 0.6501\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4101 - accuracy: 0.9349 - val_loss: 2.8161 - val_accuracy: 0.6143\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5089 - accuracy: 0.9209 - val_loss: 3.3052 - val_accuracy: 0.6219\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7056 - accuracy: 0.8757 - val_loss: 2.7414 - val_accuracy: 0.6313\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4647 - accuracy: 0.9257 - val_loss: 2.5238 - val_accuracy: 0.6512\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3964 - accuracy: 0.9383 - val_loss: 2.4827 - val_accuracy: 0.6606\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3850 - accuracy: 0.9379 - val_loss: 2.4582 - val_accuracy: 0.6524\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3809 - accuracy: 0.9392 - val_loss: 2.4547 - val_accuracy: 0.6512\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3799 - accuracy: 0.9398 - val_loss: 2.4734 - val_accuracy: 0.6518\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3794 - accuracy: 0.9401 - val_loss: 2.4652 - val_accuracy: 0.6512\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3789 - accuracy: 0.9402 - val_loss: 2.4553 - val_accuracy: 0.6506\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3786 - accuracy: 0.9405 - val_loss: 2.4583 - val_accuracy: 0.6518\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3767 - accuracy: 0.9406 - val_loss: 2.4430 - val_accuracy: 0.6460\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3764 - accuracy: 0.9406 - val_loss: 2.4666 - val_accuracy: 0.6483\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3759 - accuracy: 0.9405 - val_loss: 2.4361 - val_accuracy: 0.6460\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3756 - accuracy: 0.9406 - val_loss: 2.4682 - val_accuracy: 0.6465\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3753 - accuracy: 0.9408 - val_loss: 2.4516 - val_accuracy: 0.6448\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3751 - accuracy: 0.9406 - val_loss: 2.4781 - val_accuracy: 0.6495\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3749 - accuracy: 0.9411 - val_loss: 2.4397 - val_accuracy: 0.6448\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3748 - accuracy: 0.9408 - val_loss: 2.4690 - val_accuracy: 0.6483\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3746 - accuracy: 0.9409 - val_loss: 2.4296 - val_accuracy: 0.6424\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3744 - accuracy: 0.9409 - val_loss: 2.4901 - val_accuracy: 0.6489\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3741 - accuracy: 0.9412 - val_loss: 2.4386 - val_accuracy: 0.6430\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3740 - accuracy: 0.9411 - val_loss: 2.4709 - val_accuracy: 0.6483\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3739 - accuracy: 0.9411 - val_loss: 2.4565 - val_accuracy: 0.6436\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3739 - accuracy: 0.9411 - val_loss: 2.4671 - val_accuracy: 0.6506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3741 - accuracy: 0.9411 - val_loss: 2.4862 - val_accuracy: 0.6477\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3751 - accuracy: 0.9408 - val_loss: 2.4475 - val_accuracy: 0.6553\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3781 - accuracy: 0.9405 - val_loss: 2.5451 - val_accuracy: 0.6407\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3876 - accuracy: 0.9384 - val_loss: 2.6632 - val_accuracy: 0.6419\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4080 - accuracy: 0.9332 - val_loss: 2.8763 - val_accuracy: 0.6184\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4815 - accuracy: 0.9245 - val_loss: 3.1426 - val_accuracy: 0.6301\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5937 - accuracy: 0.9113 - val_loss: 2.6584 - val_accuracy: 0.6448\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3921 - accuracy: 0.9383 - val_loss: 2.4911 - val_accuracy: 0.6559\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3675 - accuracy: 0.9401 - val_loss: 2.5044 - val_accuracy: 0.6465\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3603 - accuracy: 0.9398 - val_loss: 2.4807 - val_accuracy: 0.6489\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3583 - accuracy: 0.9402 - val_loss: 2.4616 - val_accuracy: 0.6495\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3574 - accuracy: 0.9411 - val_loss: 2.4875 - val_accuracy: 0.6448\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3568 - accuracy: 0.9417 - val_loss: 2.4923 - val_accuracy: 0.6471\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3563 - accuracy: 0.9418 - val_loss: 2.4785 - val_accuracy: 0.6465\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3559 - accuracy: 0.9421 - val_loss: 2.4907 - val_accuracy: 0.6454\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3557 - accuracy: 0.9423 - val_loss: 2.4905 - val_accuracy: 0.6489\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3554 - accuracy: 0.9423 - val_loss: 2.4904 - val_accuracy: 0.6506\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3551 - accuracy: 0.9423 - val_loss: 2.4926 - val_accuracy: 0.6512\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3549 - accuracy: 0.9423 - val_loss: 2.4932 - val_accuracy: 0.6477\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3548 - accuracy: 0.9428 - val_loss: 2.4979 - val_accuracy: 0.6489\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3546 - accuracy: 0.9428 - val_loss: 2.5001 - val_accuracy: 0.6489\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3544 - accuracy: 0.9428 - val_loss: 2.4949 - val_accuracy: 0.6495\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3543 - accuracy: 0.9428 - val_loss: 2.5056 - val_accuracy: 0.6465\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3542 - accuracy: 0.9428 - val_loss: 2.4877 - val_accuracy: 0.6489\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3541 - accuracy: 0.9428 - val_loss: 2.5223 - val_accuracy: 0.6465\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3540 - accuracy: 0.9428 - val_loss: 2.5035 - val_accuracy: 0.6483\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3540 - accuracy: 0.9428 - val_loss: 2.4972 - val_accuracy: 0.6460\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3540 - accuracy: 0.9430 - val_loss: 2.4914 - val_accuracy: 0.6483\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3541 - accuracy: 0.9427 - val_loss: 2.5018 - val_accuracy: 0.6483\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3545 - accuracy: 0.9427 - val_loss: 2.4644 - val_accuracy: 0.6565\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3548 - accuracy: 0.9424 - val_loss: 2.4941 - val_accuracy: 0.6436\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3527 - accuracy: 0.9427 - val_loss: 2.4618 - val_accuracy: 0.6454\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3520 - accuracy: 0.9427 - val_loss: 2.4870 - val_accuracy: 0.6495\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model with the optimal combination of hyperparameters and save its training history\n",
    "# Follow the same guidelines as you have done previously to build the neural networks model\n",
    "\n",
    "# Create a neural network model with a combination of potentially optimal hyperparameter values and train the model\n",
    "nn_best = create_nn(activation_function = best_activation, hidden1_neurons = best_n_neurons)\n",
    "    \n",
    "# Capture the training history of the model\n",
    "nn_best.summary()\n",
    "print('\\n')\n",
    "nn_best_history = nn_best.fit(Tfidf_train, y_train, batch_size = Tfidf_train.shape[0], validation_split = 0.2, epochs = 200)\n",
    "hist = pd.DataFrame(nn_best_history.history)\n",
    "hist['epoch'] = nn_best_history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Show the performance results for each of the neural network models that we build\n",
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'accuracy', color = 'red', label = 'Train')\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'val_accuracy', color = 'blue', label = 'Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy as a Function of Epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnlFB4hbR_uw"
   },
   "source": [
    "### Final validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "GNb2VkMMLV1A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 2ms/step - loss: 4.1297 - accuracy: 0.5040\n",
      "The loss value of the model on the validation data is 4.129655838012695\n",
      "The accuracy of the model on the validation data is 0.5039849877357483\n"
     ]
    }
   ],
   "source": [
    "# Compute the final accuracy of the model on the validation data set using the 'evaluate()' method\n",
    "performance_test = nn_best.evaluate(Tfidf_test, y_test)\n",
    "\n",
    "print('The loss value of the model on the validation data is {}'.format(performance_test[0]))\n",
    "print('The accuracy of the model on the validation data is {}'.format(performance_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2gFD3_XNbIU"
   },
   "source": [
    "## Results\n",
    "\n",
    "- Document the results of both the conventional and the deep learning models here\n",
    "\n",
    "- Which model would you finally choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI47Vv0dTkhB"
   },
   "source": [
    "## Closing Remarks\n",
    "\n",
    "Congratulations! You have now reached the end of this assignment. With this, you are now well equipped with the skills to tackle advanced NLP problems that require DL applications as well. \n",
    "\n",
    "In fact, if you are felt that the performance of the basic neural network models left much to be desired, don't worry! In the upcoming weeks you'll learn some state of the art DL/NLP architectures such as transformers which perform significantly better and are responsible for some of the current advances in AI. We hope you have a great experience ahead!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
